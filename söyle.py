# -*- coding: utf-8 -*-
"""Söyle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D_cIq96t0ffmAGNcSkFRuZCuJ26qpIsh
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install "optimum-onnx[onnxruntime_gpu]"@git+https://github.com/huggingface/optimum-onnx.git
!pip install sentencepiece pyarrow regex huggingface-hub

"""# Код из репозитория [Söyle](https://github.com/IS2AI/Soyle?tab=readme-ov-file)"""

# Import required modules
from optimum.onnxruntime import ORTModelForSpeechSeq2Seq
from transformers import pipeline, AutoTokenizer, AutoFeatureExtractor, AutoModelForSpeechSeq2Seq

# Set parameters
model_id = 'dhcppc0/soyle_onnx'
audio_file = "/content/drive/MyDrive/Курсовая_3_курс/Голосовые/Женщина_20"
# audio_file = "test_253.wav"

lang_id = "<|tt|>"

# Load the pre-trained model with GPU support (or change to "CPUExecutionProvider" if GPU is not available)
model = ORTModelForSpeechSeq2Seq.from_pretrained(model_id, provider="CPUExecutionProvider")

# Load the tokenizer and feature_extractor
tokenizer = AutoTokenizer.from_pretrained(model_id)
feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)

# Create a pipeline for automatic speech recognition
pipe = pipeline("automatic-speech-recognition", model=model, tokenizer=tokenizer, feature_extractor=feature_extractor)

# Run inference (larger batch_size yields faster recognition, but may reduce quality)
output = pipe(audio_file, batch_size=4, generate_kwargs = {"language":lang_id})['text']
print(output)

"""# Адаптация кода под мои файлы"""

import os

audio_dir = "/content/drive/MyDrive/Курсовая_3_курс/Голосовые/Мужчина_41"   # поправь путь если нужно
wav_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith(".wav")]

print(f"Найдено {len(wav_files)} wav-файлов")

from optimum.onnxruntime import ORTModelForSpeechSeq2Seq
from transformers import pipeline, AutoTokenizer, AutoFeatureExtractor

model_id = "dhcppc0/soyle_onnx"
lang_id = "<|tt|>"

model = ORTModelForSpeechSeq2Seq.from_pretrained(model_id, provider="CUDAExecutionProvider")

tokenizer = AutoTokenizer.from_pretrained(model_id)
feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)

pipe = pipeline("automatic-speech-recognition",
                model=model,
                tokenizer=tokenizer,
                feature_extractor=feature_extractor)

"""Смотрим сколько GPU осталось"""

import torch, time

def print_gpu_usage():
    if torch.cuda.is_available():
        free, total = torch.cuda.mem_get_info()
        used = (total - free) / 1024**3
        print(f"GPU Используется: {used:.2f} GB / {total/1024**3:.2f} GB")

output_path = "/content/drive/MyDrive/Курсовая_3_курс/Голосовые/soyle_results_9.txt"

with open(output_path, "w", encoding="utf-8") as f:
    for i, wav in enumerate(wav_files, 1):
        print(f"[{i}/{len(wav_files)}] Обработка: {os.path.basename(wav)}")
        print_gpu_usage()

        try:
            text = pipe(wav, batch_size=4, generate_kwargs={"language": lang_id})['text']
        except Exception as e:
            text = f"Ошибка при обработке: {e}"

        # Запись результата в файл
        f.write(f"# id: {os.path.basename(wav)}\n{text}\n\n")

        print("Распознанный текст:", text)
        print_gpu_usage()
        print("-" * 40)

print(f"Готово! Все результаты сохранены в {output_path}")

text_dir = "/content/drive/MyDrive/Курсовая_3_курс/Голосовые/Текст"

txt_files = sorted([os.path.join(text_dir, f) for f in os.listdir(text_dir) if f.endswith(".txt")])

print(f"Найдено {len(txt_files)} файлов")

output_file = "/content/drive/MyDrive/Курсовая_3_курс/Голосовые/Текст/Объединенный_текст.txt"

with open(output_file, "w", encoding="utf-8") as outfile:
    for i, fname in enumerate(txt_files, 1):
        with open(fname, "r", encoding="utf-8") as infile:
            content = infile.read().strip()

            outfile.write(f"### Файл {os.path.basename(fname)}\n")
            outfile.write(content + "\n\n")

print(f"Файлы объединены в {output_file}")

import re

text_dir = "/content/drive/MyDrive/Курсовая_3_курс/Голосовые/Текст"

output_file = "/content/drive/MyDrive/Курсовая_3_курс/Голосовые/Текст/Объединенный_по_id_2.txt"

txt_files = sorted([os.path.join(text_dir, f) for f in os.listdir(text_dir) if f.endswith(".txt")])

entries = []

for fname in txt_files:
    with open(fname, "r", encoding="utf-8") as f:
        content = f.read().strip()

        blocks = content.split("# id:")
        for block in blocks:
            block = block.strip()
            if not block:
                continue
            # восстанавливаем строку с # id:
            block = "# id: " + block

            match = re.search(r"# id:\s*.*?(\d+)", block)
            if match:
                id_num = int(match.group(1))
                entries.append((id_num, block))

# сортируем по id
entries.sort(key=lambda x: x[0])

with open(output_file, "w", encoding="utf-8") as out:
    for _, block in entries:
        out.write(block.strip() + "\n\n")

print(f"Готово! Итоговый файл сохранён: {output_file}")