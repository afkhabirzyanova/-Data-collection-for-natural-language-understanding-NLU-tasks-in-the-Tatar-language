{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQMNgIKGn8Qq"
      },
      "source": [
        "## Machamp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJPEKQZKchyu",
        "outputId": "8a1da96f-d031-43c5-e4cd-d2abc77634fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brLK_pW0qH61",
        "outputId": "1ad47024-25bb-4aa2-d27d-cc44b282b096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'machamp'...\n",
            "remote: Enumerating objects: 2218, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 2218 (delta 131), reused 131 (delta 122), pack-reused 2040 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2218/2218), 1.83 MiB | 3.18 MiB/s, done.\n",
            "Resolving deltas: 100% (1462/1462), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/machamp-nlp/machamp.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3NywFO58omo",
        "outputId": "5dfe4d7a-f553-4f93-951f-5eafffa1b10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/machamp\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab_Notebooks/machamp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL7uhJcL8rUc",
        "outputId": "68cfcb5d-4c1a-493f-de3a-a79dff4fde33",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (4.56.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: jsonnet in /root/.local/lib/python3.12/site-packages (from -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 5)) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 6)) (0.2.1)\n",
            "Requirement already satisfied: uniplot in /root/.local/lib/python3.12/site-packages (from -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 7)) (0.21.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: readchar>=4.2.1 in /root/.local/lib/python3.12/site-packages (from uniplot->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 7)) (4.2.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.0.0->-r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt (line 1)) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --user -r /content/drive/MyDrive/Colab_Notebooks/machamp/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMp1_NVeCkwM"
      },
      "source": [
        "Скачиваем данные xSID, кладем в нужную директорию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZltiOTdZCqSs"
      },
      "outputs": [],
      "source": [
        "%mkdir data\n",
        "%mkdir data/xSID-tat/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ1QwPUHEjn9",
        "outputId": "9a9b92d4-f6aa-4b57-d169-2308157c94bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-04 09:08:39.607768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759568919.627649    3763 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759568919.634454    3763 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759568919.652003    3763 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759568919.652039    3763 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759568919.652047    3763 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759568919.652054    3763 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-04 09:08:39.657033: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-10-04 09:08:43,299 - INFO - machamp.model.trainer - cmd: /content/drive/MyDrive/Colab_Notebooks/machamp/train.py --dataset_configs /content/drive/MyDrive/Colab_Notebooks/machamp/configs/nlu.json --device 0\n",
            "2025-10-04 09:08:43,393 - INFO - machamp.model.trainer - GPU: Tesla T4\n",
            "2025-10-04 09:08:43,394 - INFO - machamp.model.trainer - Torch version: 2.8.0+cu126\n",
            "2025-10-04 09:08:43,394 - INFO - machamp.model.trainer - Transformers version: 4.56.2\n",
            "2025-10-04 09:08:43,396 - INFO - machamp.model.trainer - MaChAmp git version 75fbbee9db00154bfefb3b0e8e1f5e1dae60694f\n",
            "2025-10-04 09:08:43,549 - ERROR - STDERR - \n",
            "2025-10-04 09:08:43,549 - ERROR - STDERR - tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]\n",
            "2025-10-04 09:08:43,550 - ERROR - STDERR - \n",
            "2025-10-04 09:08:43,550 - ERROR - STDERR - tokenizer_config.json: 100%|##########| 52.0/52.0 [00:00<00:00, 250kB/s]\n",
            "2025-10-04 09:08:43,674 - ERROR - STDERR - \n",
            "2025-10-04 09:08:43,674 - ERROR - STDERR - config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]\n",
            "2025-10-04 09:08:43,675 - ERROR - STDERR - \n",
            "2025-10-04 09:08:43,675 - ERROR - STDERR - config.json: 100%|##########| 579/579 [00:00<00:00, 3.87MB/s]\n",
            "2025-10-04 09:08:44,064 - ERROR - STDERR - \n",
            "2025-10-04 09:08:44,064 - ERROR - STDERR - spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]\n",
            "2025-10-04 09:08:44,593 - ERROR - STDERR - \n",
            "2025-10-04 09:08:44,595 - ERROR - STDERR - spm.model: 100%|##########| 4.31M/4.31M [00:00<00:00, 8.15MB/s]\n",
            "2025-10-04 09:08:44,596 - ERROR - STDERR - \n",
            "2025-10-04 09:08:44,596 - ERROR - STDERR - spm.model: 100%|##########| 4.31M/4.31M [00:00<00:00, 8.11MB/s]\n",
            "2025-10-04 09:08:45,825 - INFO - machamp.data.machamp_dataset - Reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/en.train.conll...\n",
            "2025-10-04 09:09:30,967 - INFO - machamp.readers.read_sequence - Stats NLU (/content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/en.train.conll):\n",
            "2025-10-04 09:09:30,967 - INFO - machamp.readers.read_sequence - Lines:      43,605\n",
            "2025-10-04 09:09:30,967 - INFO - machamp.readers.read_sequence - Words:      341,184\n",
            "2025-10-04 09:09:30,968 - INFO - machamp.readers.read_sequence - Subwords:   449,359\n",
            "2025-10-04 09:09:30,968 - INFO - machamp.readers.read_sequence - Unks:       0\n",
            "2025-10-04 09:09:30,968 - INFO - machamp.readers.read_sequence - Pre-splits: 0\n",
            "2025-10-04 09:09:30,982 - INFO - machamp.data.machamp_dataset - Done reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/en.train.conll (45.0s)\n",
            "\n",
            "2025-10-04 09:09:32,267 - INFO - machamp.data.machamp_dataset - Reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/final_not_full_tat.valid.conll...\n",
            "2025-10-04 09:09:32,357 - INFO - machamp.readers.read_sequence - Stats NLU (/content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/final_not_full_tat.valid.conll):\n",
            "2025-10-04 09:09:32,358 - INFO - machamp.readers.read_sequence - Lines:      100\n",
            "2025-10-04 09:09:32,358 - INFO - machamp.readers.read_sequence - Words:      622\n",
            "2025-10-04 09:09:32,358 - INFO - machamp.readers.read_sequence - Subwords:   1,438\n",
            "2025-10-04 09:09:32,358 - INFO - machamp.readers.read_sequence - Unks:       0\n",
            "2025-10-04 09:09:32,359 - INFO - machamp.readers.read_sequence - Pre-splits: 0\n",
            "2025-10-04 09:09:32,359 - INFO - machamp.data.machamp_dataset - Done reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/final_not_full_tat.valid.conll (0.0s)\n",
            "\n",
            "2025-10-04 09:09:35,180 - ERROR - STDERR - \n",
            "2025-10-04 09:09:35,180 - ERROR - STDERR - pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]\n",
            "2025-10-04 09:09:36,279 - ERROR - STDERR - \n",
            "2025-10-04 09:09:36,280 - ERROR - STDERR - pytorch_model.bin:   0%|          | 1.25M/1.33G [00:01<19:26, 1.14MB/s]\n",
            "2025-10-04 09:09:39,694 - ERROR - STDERR - \n",
            "2025-10-04 09:09:39,695 - ERROR - STDERR - pytorch_model.bin:   5%|5         | 68.3M/1.33G [00:04<01:17, 16.2MB/s]\n",
            "2025-10-04 09:09:40,436 - ERROR - STDERR - \n",
            "2025-10-04 09:09:40,438 - ERROR - STDERR - pytorch_model.bin:  10%|#         | 136M/1.33G [00:05<00:38, 31.3MB/s]\n",
            "2025-10-04 09:09:45,321 - ERROR - STDERR - \n",
            "2025-10-04 09:09:45,324 - ERROR - STDERR - pytorch_model.bin:  15%|#5        | 203M/1.33G [00:10<00:57, 19.8MB/s]\n",
            "2025-10-04 09:09:49,222 - ERROR - STDERR - \n",
            "2025-10-04 09:09:49,223 - ERROR - STDERR - pytorch_model.bin:  20%|##        | 270M/1.33G [00:14<00:56, 18.7MB/s]\n",
            "2025-10-04 09:09:55,378 - ERROR - STDERR - \n",
            "2025-10-04 09:09:55,378 - ERROR - STDERR - pytorch_model.bin:  30%|###       | 404M/1.33G [00:20<00:46, 20.2MB/s]\n",
            "2025-10-04 09:09:56,154 - ERROR - STDERR - \n",
            "2025-10-04 09:09:56,154 - ERROR - STDERR - pytorch_model.bin:  40%|####      | 538M/1.33G [00:20<00:24, 32.6MB/s]\n",
            "2025-10-04 09:09:56,612 - ERROR - STDERR - \n",
            "2025-10-04 09:09:56,613 - ERROR - STDERR - pytorch_model.bin:  45%|####5     | 605M/1.33G [00:21<00:18, 39.9MB/s]\n",
            "2025-10-04 09:09:57,185 - ERROR - STDERR - \n",
            "2025-10-04 09:09:57,188 - ERROR - STDERR - pytorch_model.bin:  50%|#####     | 672M/1.33G [00:22<00:13, 47.8MB/s]\n",
            "2025-10-04 09:09:57,719 - ERROR - STDERR - \n",
            "2025-10-04 09:09:57,722 - ERROR - STDERR - pytorch_model.bin:  55%|#####5    | 739M/1.33G [00:22<00:10, 57.1MB/s]\n",
            "2025-10-04 09:09:58,024 - ERROR - STDERR - \n",
            "2025-10-04 09:09:58,025 - ERROR - STDERR - pytorch_model.bin:  60%|######    | 804M/1.33G [00:22<00:07, 71.3MB/s]\n",
            "2025-10-04 09:09:58,518 - ERROR - STDERR - \n",
            "2025-10-04 09:09:58,519 - ERROR - STDERR - pytorch_model.bin:  65%|######5   | 871M/1.33G [00:23<00:05, 82.3MB/s]\n",
            "2025-10-04 09:09:59,250 - ERROR - STDERR - \n",
            "2025-10-04 09:09:59,251 - ERROR - STDERR - pytorch_model.bin:  70%|######9   | 931M/1.33G [00:24<00:04, 81.9MB/s]\n",
            "2025-10-04 09:09:59,546 - ERROR - STDERR - \n",
            "2025-10-04 09:09:59,547 - ERROR - STDERR - pytorch_model.bin:  75%|#######4  | 998M/1.33G [00:24<00:03, 101MB/s]\n",
            "2025-10-04 09:09:59,993 - ERROR - STDERR - \n",
            "2025-10-04 09:09:59,994 - ERROR - STDERR - pytorch_model.bin:  80%|#######9  | 1.06G/1.33G [00:24<00:02, 112MB/s]\n",
            "2025-10-04 09:10:00,608 - ERROR - STDERR - \n",
            "2025-10-04 09:10:00,609 - ERROR - STDERR - pytorch_model.bin:  85%|########4 | 1.13G/1.33G [00:25<00:01, 111MB/s]\n",
            "2025-10-04 09:10:01,092 - ERROR - STDERR - \n",
            "2025-10-04 09:10:01,093 - ERROR - STDERR - pytorch_model.bin:  90%|########9 | 1.20G/1.33G [00:25<00:01, 118MB/s]\n",
            "2025-10-04 09:10:03,589 - ERROR - STDERR - \n",
            "2025-10-04 09:10:03,590 - ERROR - STDERR - pytorch_model.bin:  95%|#########4| 1.27G/1.33G [00:28<00:01, 58.5MB/s]\n",
            "2025-10-04 09:10:03,674 - ERROR - STDERR - \n",
            "2025-10-04 09:10:03,677 - ERROR - STDERR - pytorch_model.bin: 100%|##########| 1.33G/1.33G [00:28<00:00, 46.8MB/s]\n",
            "2025-10-04 09:10:04,759 - ERROR - STDERR - \n",
            "2025-10-04 09:10:04,764 - ERROR - STDERR - model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]\n",
            "2025-10-04 09:10:05,982 - ERROR - STDERR - \n",
            "2025-10-04 09:10:05,990 - ERROR - STDERR - model.safetensors:   0%|          | 679k/1.33G [00:01<39:46, 558kB/s]\n",
            "2025-10-04 09:10:06,204 - ERROR - STDERR - \n",
            "2025-10-04 09:10:06,217 - ERROR - STDERR - model.safetensors:   0%|          | 1.69M/1.33G [00:01<16:02, 1.38MB/s]\n",
            "2025-10-04 09:10:06,305 - ERROR - STDERR - \n",
            "2025-10-04 09:10:06,306 - ERROR - STDERR - model.safetensors:   0%|          | 4.98M/1.33G [00:01<04:21, 5.07MB/s]\n",
            "2025-10-04 09:10:06,406 - ERROR - STDERR - \n",
            "2025-10-04 09:10:06,413 - ERROR - STDERR - model.safetensors:   1%|          | 11.5M/1.33G [00:01<01:36, 13.7MB/s]\n",
            "2025-10-04 09:10:06,508 - ERROR - STDERR - \n",
            "2025-10-04 09:10:06,510 - ERROR - STDERR - model.safetensors:   2%|1         | 25.3M/1.33G [00:01<00:37, 34.7MB/s]\n",
            "2025-10-04 09:10:06,619 - ERROR - STDERR - \n",
            "2025-10-04 09:10:06,620 - ERROR - STDERR - model.safetensors:   3%|3         | 41.0M/1.33G [00:01<00:22, 57.3MB/s]\n",
            "2025-10-04 09:10:06,761 - ERROR - STDERR - \n",
            "2025-10-04 09:10:06,763 - ERROR - STDERR - model.safetensors:   5%|4         | 64.5M/1.33G [00:01<00:14, 87.4MB/s]\n",
            "2025-10-04 09:10:06,892 - ERROR - STDERR - \n",
            "2025-10-04 09:10:06,893 - ERROR - STDERR - model.safetensors:   6%|5         | 77.3M/1.33G [00:02<00:13, 90.2MB/s]\n",
            "2025-10-04 09:10:07,137 - ERROR - STDERR - \n",
            "2025-10-04 09:10:07,138 - ERROR - STDERR - model.safetensors:   7%|6         | 91.7M/1.33G [00:02<00:16, 77.2MB/s]\n",
            "2025-10-04 09:10:07,314 - ERROR - STDERR - \n",
            "2025-10-04 09:10:07,315 - ERROR - STDERR - model.safetensors:   8%|7         | 104M/1.33G [00:02<00:16, 74.9MB/s]\n",
            "2025-10-04 09:10:08,617 - INFO - machamp.model.machamp - Overview of the torch model: \n",
            "2025-10-04 09:10:08,618 - INFO - machamp.model.machamp - MachampModel(\n",
            "  (mlm): DebertaV2Model(\n",
            "    (embeddings): DebertaV2Embeddings(\n",
            "      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): DebertaV2Encoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (rel_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (decoders): ModuleDict(\n",
            "    (intent): MachampClassificationDecoder(\n",
            "      (hidden_to_label): Linear(in_features=768, out_features=19, bias=True)\n",
            "      (loss_function): CrossEntropyLoss()\n",
            "      (decoder_dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (slots): MachampSeqDecoder(\n",
            "      (hidden_to_label): Linear(in_features=768, out_features=73, bias=True)\n",
            "      (loss_function): CrossEntropyLoss()\n",
            "      (decoder_dropout): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (scalars): ModuleDict(\n",
            "    (intent): None\n",
            "    (slots): None\n",
            "  )\n",
            ")\n",
            "2025-10-04 09:10:08,659 - INFO - machamp.utils.myutils - Done constructing parameter groups.\n",
            "2025-10-04 09:10:08,661 - INFO - machamp.utils.myutils - Group 0: ['mlm.encoder.layer.5.attention.self.key_proj.weight', 'mlm.encoder.layer.10.output.LayerNorm.weight', 'mlm.encoder.layer.1.attention.output.dense.bias', 'mlm.encoder.layer.10.attention.output.dense.bias', 'mlm.encoder.layer.9.attention.self.key_proj.weight', 'mlm.encoder.layer.1.attention.self.key_proj.weight', 'mlm.embeddings.LayerNorm.weight', 'mlm.encoder.layer.6.output.dense.bias', 'mlm.encoder.layer.4.attention.self.value_proj.bias', 'mlm.encoder.layer.8.output.dense.weight', 'mlm.encoder.layer.3.intermediate.dense.weight', 'mlm.encoder.layer.6.output.dense.weight', 'mlm.encoder.layer.9.output.LayerNorm.bias', 'mlm.encoder.layer.7.attention.self.value_proj.weight', 'mlm.encoder.layer.5.output.LayerNorm.bias', 'mlm.encoder.layer.1.attention.output.LayerNorm.bias', 'mlm.encoder.layer.8.attention.self.query_proj.bias', 'mlm.encoder.layer.7.attention.self.key_proj.weight', 'mlm.encoder.layer.0.intermediate.dense.bias', 'mlm.encoder.layer.1.attention.self.value_proj.weight', 'mlm.encoder.layer.2.attention.self.key_proj.bias', 'mlm.encoder.layer.11.attention.self.value_proj.bias', 'mlm.encoder.layer.8.output.LayerNorm.weight', 'mlm.encoder.layer.4.output.LayerNorm.bias', 'mlm.encoder.layer.5.output.dense.bias', 'mlm.encoder.layer.3.attention.self.query_proj.bias', 'mlm.encoder.layer.4.attention.output.LayerNorm.weight', 'mlm.encoder.layer.5.attention.self.key_proj.bias', 'mlm.encoder.layer.9.attention.self.query_proj.weight', 'mlm.encoder.layer.10.attention.self.value_proj.bias', 'mlm.encoder.layer.5.output.dense.weight', 'mlm.encoder.layer.7.intermediate.dense.weight', 'mlm.encoder.layer.9.intermediate.dense.weight', 'mlm.encoder.layer.5.intermediate.dense.weight', 'mlm.encoder.layer.7.output.LayerNorm.weight', 'mlm.encoder.layer.0.output.dense.bias', 'mlm.encoder.layer.7.attention.output.dense.weight', 'mlm.encoder.layer.11.intermediate.dense.bias', 'mlm.encoder.layer.11.output.dense.bias', 'mlm.encoder.layer.7.attention.output.LayerNorm.bias', 'mlm.encoder.layer.1.attention.self.value_proj.bias', 'mlm.encoder.layer.11.output.dense.weight', 'mlm.encoder.layer.10.attention.self.value_proj.weight', 'mlm.encoder.layer.6.attention.output.LayerNorm.weight', 'mlm.encoder.layer.4.attention.self.key_proj.bias', 'mlm.encoder.layer.9.output.LayerNorm.weight', 'mlm.encoder.LayerNorm.bias', 'mlm.encoder.layer.3.output.LayerNorm.bias', 'mlm.encoder.layer.4.attention.self.query_proj.bias', 'mlm.encoder.layer.6.attention.self.value_proj.bias', 'mlm.encoder.layer.10.output.dense.weight', 'mlm.encoder.rel_embeddings.weight', 'mlm.encoder.layer.11.attention.output.dense.weight', 'mlm.encoder.layer.3.attention.self.key_proj.bias', 'mlm.encoder.layer.3.attention.self.value_proj.weight', 'mlm.encoder.layer.5.attention.output.LayerNorm.bias', 'mlm.encoder.layer.6.attention.self.query_proj.weight', 'mlm.encoder.layer.6.attention.output.LayerNorm.bias', 'mlm.encoder.layer.0.intermediate.dense.weight', 'mlm.encoder.layer.7.attention.output.dense.bias', 'mlm.encoder.layer.6.intermediate.dense.weight', 'mlm.encoder.layer.0.attention.self.query_proj.weight', 'mlm.encoder.layer.2.attention.self.query_proj.weight', 'mlm.encoder.layer.3.attention.output.LayerNorm.bias', 'mlm.encoder.layer.0.attention.output.LayerNorm.bias', 'mlm.encoder.layer.4.intermediate.dense.weight', 'mlm.encoder.layer.11.attention.output.LayerNorm.bias', 'mlm.encoder.layer.11.attention.output.dense.bias', 'mlm.encoder.layer.2.attention.self.value_proj.weight', 'mlm.encoder.layer.11.intermediate.dense.weight', 'mlm.encoder.layer.1.attention.output.dense.weight', 'mlm.encoder.layer.1.output.dense.weight', 'mlm.encoder.layer.6.attention.self.key_proj.bias', 'mlm.encoder.layer.6.attention.self.value_proj.weight', 'mlm.encoder.layer.0.output.dense.weight', 'mlm.encoder.layer.11.output.LayerNorm.weight', 'mlm.encoder.layer.1.intermediate.dense.weight', 'mlm.encoder.layer.4.attention.self.value_proj.weight', 'mlm.encoder.layer.8.attention.output.dense.bias', 'mlm.encoder.layer.11.attention.self.key_proj.bias', 'mlm.encoder.layer.3.output.dense.weight', 'mlm.encoder.layer.11.attention.self.query_proj.weight', 'mlm.encoder.layer.8.attention.self.key_proj.bias', 'mlm.encoder.layer.11.attention.self.key_proj.weight', 'mlm.encoder.layer.0.attention.output.dense.bias', 'mlm.encoder.layer.0.attention.self.key_proj.bias', 'mlm.encoder.layer.7.attention.output.LayerNorm.weight', 'mlm.encoder.layer.6.attention.self.key_proj.weight', 'mlm.encoder.layer.8.output.LayerNorm.bias', 'mlm.encoder.layer.4.output.dense.bias', 'mlm.encoder.layer.10.output.LayerNorm.bias', 'mlm.encoder.layer.7.attention.self.value_proj.bias', 'mlm.encoder.layer.9.attention.self.key_proj.bias', 'mlm.encoder.layer.2.attention.output.LayerNorm.bias', 'mlm.encoder.layer.0.attention.self.value_proj.weight', 'mlm.encoder.layer.6.attention.self.query_proj.bias', 'mlm.encoder.layer.6.output.LayerNorm.weight', 'mlm.embeddings.word_embeddings.weight', 'mlm.encoder.layer.8.attention.self.query_proj.weight', 'mlm.encoder.layer.5.attention.self.value_proj.weight', 'mlm.encoder.layer.4.intermediate.dense.bias', 'mlm.encoder.layer.5.attention.self.value_proj.bias', 'mlm.encoder.layer.10.attention.self.query_proj.weight', 'mlm.encoder.layer.10.attention.self.query_proj.bias', 'mlm.encoder.layer.9.attention.output.dense.bias', 'mlm.encoder.layer.8.attention.output.dense.weight', 'mlm.encoder.layer.3.attention.output.dense.weight', 'mlm.encoder.layer.8.attention.output.LayerNorm.bias', 'mlm.encoder.layer.2.intermediate.dense.weight', 'mlm.encoder.layer.9.output.dense.weight', 'mlm.encoder.layer.2.attention.output.dense.weight', 'mlm.encoder.layer.1.output.LayerNorm.weight', 'mlm.encoder.layer.1.attention.self.query_proj.weight', 'mlm.encoder.layer.3.attention.output.dense.bias', 'mlm.encoder.layer.2.output.LayerNorm.weight', 'mlm.encoder.layer.4.output.LayerNorm.weight', 'mlm.encoder.layer.9.intermediate.dense.bias', 'mlm.encoder.LayerNorm.weight', 'mlm.encoder.layer.0.output.LayerNorm.weight', 'mlm.encoder.layer.2.output.LayerNorm.bias', 'mlm.encoder.layer.8.intermediate.dense.weight', 'mlm.encoder.layer.10.intermediate.dense.weight', 'mlm.encoder.layer.11.output.LayerNorm.bias', 'mlm.encoder.layer.7.attention.self.query_proj.weight', 'mlm.encoder.layer.7.intermediate.dense.bias', 'mlm.encoder.layer.2.attention.output.LayerNorm.weight', 'mlm.embeddings.LayerNorm.bias', 'mlm.encoder.layer.5.output.LayerNorm.weight', 'mlm.encoder.layer.10.output.dense.bias', 'mlm.encoder.layer.1.output.dense.bias', 'mlm.encoder.layer.4.attention.self.query_proj.weight', 'mlm.encoder.layer.3.output.LayerNorm.weight', 'mlm.encoder.layer.8.attention.self.value_proj.bias', 'mlm.encoder.layer.10.intermediate.dense.bias', 'mlm.encoder.layer.2.attention.self.key_proj.weight', 'mlm.encoder.layer.6.intermediate.dense.bias', 'mlm.encoder.layer.7.attention.self.key_proj.bias', 'mlm.encoder.layer.0.attention.self.key_proj.weight', 'mlm.encoder.layer.6.attention.output.dense.bias', 'mlm.encoder.layer.7.output.LayerNorm.bias', 'mlm.encoder.layer.4.attention.output.dense.bias', 'mlm.encoder.layer.9.attention.output.dense.weight', 'mlm.encoder.layer.1.intermediate.dense.bias', 'mlm.encoder.layer.4.output.dense.weight', 'mlm.encoder.layer.2.attention.self.query_proj.bias', 'mlm.encoder.layer.4.attention.self.key_proj.weight', 'mlm.encoder.layer.5.attention.output.LayerNorm.weight', 'mlm.encoder.layer.4.attention.output.LayerNorm.bias', 'mlm.encoder.layer.8.attention.self.value_proj.weight', 'mlm.encoder.layer.0.attention.self.value_proj.bias', 'mlm.encoder.layer.1.output.LayerNorm.bias', 'mlm.encoder.layer.5.intermediate.dense.bias', 'mlm.encoder.layer.5.attention.self.query_proj.weight', 'mlm.encoder.layer.7.attention.self.query_proj.bias', 'mlm.encoder.layer.2.output.dense.bias', 'mlm.encoder.layer.0.output.LayerNorm.bias', 'mlm.encoder.layer.2.output.dense.weight', 'mlm.encoder.layer.3.attention.self.key_proj.weight', 'mlm.encoder.layer.3.attention.self.query_proj.weight', 'mlm.encoder.layer.9.attention.output.LayerNorm.weight', 'mlm.encoder.layer.10.attention.output.dense.weight', 'mlm.encoder.layer.7.output.dense.bias', 'mlm.encoder.layer.4.attention.output.dense.weight', 'mlm.encoder.layer.5.attention.self.query_proj.bias', 'mlm.encoder.layer.2.attention.self.value_proj.bias', 'mlm.encoder.layer.2.intermediate.dense.bias', 'mlm.encoder.layer.10.attention.output.LayerNorm.weight', 'mlm.encoder.layer.8.attention.self.key_proj.weight', 'mlm.encoder.layer.11.attention.self.value_proj.weight', 'mlm.encoder.layer.3.attention.self.value_proj.bias', 'mlm.encoder.layer.7.output.dense.weight', 'mlm.encoder.layer.3.output.dense.bias', 'mlm.encoder.layer.10.attention.self.key_proj.bias', 'mlm.encoder.layer.11.attention.self.query_proj.bias', 'mlm.encoder.layer.9.attention.self.value_proj.weight', 'mlm.encoder.layer.9.attention.self.value_proj.bias', 'mlm.encoder.layer.10.attention.output.LayerNorm.bias', 'mlm.encoder.layer.10.attention.self.key_proj.weight', 'mlm.encoder.layer.5.attention.output.dense.weight', 'mlm.encoder.layer.1.attention.self.key_proj.bias', 'mlm.encoder.layer.3.intermediate.dense.bias', 'mlm.encoder.layer.6.attention.output.dense.weight', 'mlm.encoder.layer.8.output.dense.bias', 'mlm.encoder.layer.0.attention.output.LayerNorm.weight', 'mlm.encoder.layer.0.attention.self.query_proj.bias', 'mlm.encoder.layer.1.attention.self.query_proj.bias', 'mlm.encoder.layer.3.attention.output.LayerNorm.weight', 'mlm.encoder.layer.9.attention.self.query_proj.bias', 'mlm.encoder.layer.5.attention.output.dense.bias', 'mlm.encoder.layer.9.attention.output.LayerNorm.bias', 'mlm.encoder.layer.11.attention.output.LayerNorm.weight', 'mlm.encoder.layer.9.output.dense.bias', 'mlm.encoder.layer.2.attention.output.dense.bias', 'mlm.encoder.layer.0.attention.output.dense.weight', 'mlm.encoder.layer.8.intermediate.dense.bias', 'mlm.encoder.layer.8.attention.output.LayerNorm.weight', 'mlm.encoder.layer.6.output.LayerNorm.bias', 'mlm.encoder.layer.1.attention.output.LayerNorm.weight'], {}\n",
            "2025-10-04 09:10:08,683 - INFO - machamp.utils.myutils - Group 1: ['decoders.intent.hidden_to_label.weight', 'decoders.intent.hidden_to_label.bias', 'decoders.slots.hidden_to_label.weight', 'decoders.slots.hidden_to_label.bias'], {}\n",
            "2025-10-04 09:10:08,684 - INFO - machamp.utils.myutils - Group 2: [], {}\n",
            "2025-10-04 09:10:08,684 - INFO - machamp.utils.myutils - Number of trainable parameters: 278289500\n",
            "2025-10-04 09:10:08,685 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing. Training only the decoder heads, not the MLM.\n",
            "2025-10-04 09:10:08,687 - INFO - machamp.model.trainer - MaChAmp succesfully initialized in 85.0s\n",
            "2025-10-04 09:10:08,687 - INFO - machamp.model.trainer - \n",
            "\n",
            "          CHAMP!                   %%#/   \n",
            " ###/%(        CHAMP!            ,#//(%%#( \n",
            "#%%/((/(            . , ,       .%%#####%(\n",
            "#(/(((###(        ////////%     *//((((((/\n",
            "  ,((((//        #%(%#/#%%/          &####\n",
            "     ###### *#%%@&((//&@#%&(%%#%%%%#%%####\n",
            "     ,####(%%###%#&&&#((&&(((%%%%########(\n",
            "       ///((%%%##/%%######((%%%%%%%%((((//\n",
            "          %%%%%##((/%(///%%##%%%%%%%##    \n",
            "        /%%####%%%%%%#%%#/(%#(((%%%%%&.   \n",
            "       &#%/#%%###%%%##%%%((###(//(####(   \n",
            "     @&%%#////(########%######((/(////(   \n",
            "       #////     ((((##(((((////,         \n",
            "                   */(//(((/**,.          \n",
            "                  #,**%#%,*,,,*(          \n",
            "               /%%%%%/,,,,,(%%%%((        \n",
            "              &%%%#(((/*  /(#%%%#(/       \n",
            "              %%#(((//     ,((###(/       \n",
            "             .%(/(/,         /(###/(      \n",
            "              %(((//          (/((///     \n",
            "               ((/,             /(//      \n",
            "             %%%#((,            &%%%#     \n",
            "         /#(#%(/,             /###*##*    \n",
            "\n",
            "2025-10-04 09:10:08,688 - INFO - machamp.model.trainer - starting training...\n",
            "2025-10-04 09:10:08,688 - INFO - machamp.model.trainer - Epoch 1/10: training\n",
            "\n",
            "  0% 0/1363 [00:00<?, ?it/s]\u001b[A2025-10-04 09:10:09,849 - ERROR - STDERR - \n",
            "2025-10-04 09:10:09,850 - ERROR - STDERR - model.safetensors:  13%|#3        | 175M/1.33G [00:05<00:33, 34.6MB/s]\n",
            "2025-10-04 09:10:09,971 - ERROR - STDERR - \n",
            "2025-10-04 09:10:09,975 - ERROR - STDERR - model.safetensors:  14%|#4        | 189M/1.33G [00:05<00:29, 39.1MB/s]\n",
            "2025-10-04 09:10:10,109 - ERROR - STDERR - \n",
            "2025-10-04 09:10:10,111 - ERROR - STDERR - model.safetensors:  15%|#5        | 201M/1.33G [00:05<00:26, 42.8MB/s]\n",
            "2025-10-04 09:10:10,220 - ERROR - STDERR - \n",
            "2025-10-04 09:10:10,221 - ERROR - STDERR - model.safetensors:  17%|#7        | 228M/1.33G [00:05<00:18, 60.3MB/s]\n",
            "2025-10-04 09:10:10,363 - ERROR - STDERR - \n",
            "2025-10-04 09:10:10,366 - ERROR - STDERR - model.safetensors:  18%|#8        | 245M/1.33G [00:05<00:15, 68.0MB/s]\n",
            "2025-10-04 09:10:10,997 - ERROR - STDERR - \n",
            "2025-10-04 09:10:10,998 - ERROR - STDERR - model.safetensors:  19%|#9        | 260M/1.33G [00:06<00:22, 47.4MB/s]\n",
            "\n",
            "  0% 1/1363 [00:02<1:07:36,  2.98s/it]\u001b[A2025-10-04 09:10:11,879 - ERROR - STDERR - \n",
            "2025-10-04 09:10:11,885 - ERROR - STDERR - model.safetensors:  22%|##2       | 295M/1.33G [00:07<00:23, 44.1MB/s]\n",
            "\n",
            "  0% 2/1363 [00:05<1:06:33,  2.93s/it]\u001b[A\n",
            "  0% 3/1363 [00:06<38:28,  1.70s/it]  \u001b[A\n",
            "  0% 4/1363 [00:06<27:48,  1.23s/it]\u001b[A\n",
            "  0% 5/1363 [00:06<18:38,  1.21it/s]\u001b[A\n",
            "  1% 7/1363 [00:06<09:59,  2.26it/s]\u001b[A\n",
            "  1% 9/1363 [00:07<06:26,  3.50it/s]\u001b[A2025-10-04 09:10:15,863 - ERROR - STDERR - \n",
            "2025-10-04 09:10:15,865 - ERROR - STDERR - model.safetensors:  26%|##5       | 343M/1.33G [00:11<00:50, 19.7MB/s]\n",
            "\n",
            "  1% 11/1363 [00:07<04:46,  4.72it/s]\u001b[A2025-10-04 09:10:16,330 - ERROR - STDERR - \n",
            "2025-10-04 09:10:16,331 - ERROR - STDERR - model.safetensors:  31%|###       | 410M/1.33G [00:11<00:27, 33.6MB/s]\n",
            "\n",
            "  1% 13/1363 [00:07<04:58,  4.52it/s]\u001b[A\n",
            "  1% 14/1363 [00:07<04:44,  4.75it/s]\u001b[A\n",
            "  1% 15/1363 [00:07<04:23,  5.12it/s]\u001b[A\n",
            "  1% 16/1363 [00:08<03:55,  5.73it/s]\u001b[A\n",
            "  1% 18/1363 [00:08<03:01,  7.41it/s]\u001b[A\n",
            "  1% 20/1363 [00:08<02:24,  9.29it/s]\u001b[A\n",
            "  2% 22/1363 [00:08<02:03, 10.82it/s]\u001b[A\n",
            "  2% 24/1363 [00:08<01:49, 12.20it/s]\u001b[A\n",
            "  2% 26/1363 [00:08<01:42, 13.01it/s]\u001b[A\n",
            "  2% 28/1363 [00:08<01:37, 13.67it/s]\u001b[A\n",
            "  2% 30/1363 [00:08<01:34, 14.12it/s]\u001b[A2025-10-04 09:10:17,841 - ERROR - STDERR - \n",
            "2025-10-04 09:10:17,842 - ERROR - STDERR - model.safetensors:  35%|###4      | 462M/1.33G [00:13<00:25, 33.9MB/s]\n",
            "\n",
            "  2% 32/1363 [00:09<02:14,  9.90it/s]\u001b[A2025-10-04 09:10:18,096 - ERROR - STDERR - \n",
            "2025-10-04 09:10:18,099 - ERROR - STDERR - model.safetensors:  40%|###9      | 529M/1.33G [00:13<00:15, 51.3MB/s]\n",
            "\n",
            "  2% 34/1363 [00:09<03:05,  7.16it/s]\u001b[A\n",
            "  3% 35/1363 [00:09<03:09,  7.01it/s]\u001b[A\n",
            "  3% 36/1363 [00:10<03:00,  7.34it/s]\u001b[A\n",
            "  3% 37/1363 [00:10<02:56,  7.50it/s]\u001b[A\n",
            "  3% 38/1363 [00:10<02:52,  7.67it/s]\u001b[A2025-10-04 09:10:19,060 - ERROR - STDERR - \n",
            "2025-10-04 09:10:19,060 - ERROR - STDERR - model.safetensors:  45%|####4     | 596M/1.33G [00:14<00:13, 56.6MB/s]\n",
            "\n",
            "  3% 39/1363 [00:10<02:48,  7.84it/s]\u001b[A\n",
            "  3% 40/1363 [00:10<02:43,  8.08it/s]\u001b[A\n",
            "  3% 41/1363 [00:10<02:37,  8.38it/s]\u001b[A2025-10-04 09:10:19,405 - ERROR - STDERR - \n",
            "2025-10-04 09:10:19,406 - ERROR - STDERR - model.safetensors:  50%|####9     | 663M/1.33G [00:14<00:09, 74.4MB/s]\n",
            "\n",
            "  3% 42/1363 [00:10<02:30,  8.76it/s]\u001b[A\n",
            "  3% 43/1363 [00:10<02:37,  8.39it/s]\u001b[A\n",
            "  3% 45/1363 [00:11<02:16,  9.63it/s]\u001b[A\n",
            "  3% 47/1363 [00:11<02:03, 10.67it/s]\u001b[A\n",
            "  4% 49/1363 [00:11<02:07, 10.31it/s]\u001b[A\n",
            "  4% 51/1363 [00:11<01:57, 11.19it/s]\u001b[A2025-10-04 09:10:20,375 - ERROR - STDERR - \n",
            "2025-10-04 09:10:20,380 - ERROR - STDERR - model.safetensors:  55%|#####4    | 730M/1.33G [00:15<00:08, 72.6MB/s]\n",
            "\n",
            "  4% 53/1363 [00:11<01:52, 11.65it/s]\u001b[A\n",
            "  4% 55/1363 [00:11<01:48, 12.08it/s]\u001b[A\n",
            "  4% 57/1363 [00:11<01:37, 13.42it/s]\u001b[A\n",
            "  4% 59/1363 [00:12<01:28, 14.69it/s]\u001b[A\n",
            "  4% 61/1363 [00:12<01:26, 15.07it/s]\u001b[A\n",
            "  5% 63/1363 [00:12<01:20, 16.14it/s]\u001b[A\n",
            "  5% 65/1363 [00:12<01:20, 16.16it/s]\u001b[A\n",
            "  5% 67/1363 [00:12<01:22, 15.65it/s]\u001b[A\n",
            "  5% 69/1363 [00:12<01:23, 15.59it/s]\u001b[A\n",
            "  5% 71/1363 [00:12<01:24, 15.35it/s]\u001b[A\n",
            "  5% 73/1363 [00:12<01:22, 15.73it/s]\u001b[A\n",
            "  6% 75/1363 [00:13<01:21, 15.89it/s]\u001b[A\n",
            "  6% 77/1363 [00:13<01:24, 15.18it/s]\u001b[A\n",
            "  6% 79/1363 [00:13<01:20, 15.99it/s]\u001b[A\n",
            "  6% 81/1363 [00:13<01:19, 16.19it/s]\u001b[A\n",
            "  6% 83/1363 [00:13<01:16, 16.67it/s]\u001b[A\n",
            "  6% 85/1363 [00:13<01:13, 17.37it/s]\u001b[A\n",
            "  6% 87/1363 [00:13<01:12, 17.50it/s]\u001b[A\n",
            "  7% 89/1363 [00:13<01:14, 17.08it/s]\u001b[A\n",
            "  7% 91/1363 [00:14<01:16, 16.58it/s]\u001b[A\n",
            "  7% 93/1363 [00:14<01:23, 15.27it/s]\u001b[A\n",
            "  7% 95/1363 [00:14<01:18, 16.13it/s]\u001b[A\n",
            "  7% 97/1363 [00:14<01:18, 16.10it/s]\u001b[A\n",
            "  7% 99/1363 [00:14<01:20, 15.71it/s]\u001b[A\n",
            "  7% 101/1363 [00:14<01:16, 16.42it/s]\u001b[A\n",
            "  8% 103/1363 [00:14<01:19, 15.88it/s]\u001b[A\n",
            "  8% 105/1363 [00:14<01:23, 15.01it/s]\u001b[A\n",
            "  8% 107/1363 [00:15<01:26, 14.48it/s]\u001b[A\n",
            "  8% 109/1363 [00:15<01:26, 14.55it/s]\u001b[A\n",
            "  8% 111/1363 [00:15<01:25, 14.63it/s]\u001b[A\n",
            "  8% 113/1363 [00:15<01:25, 14.70it/s]\u001b[A\n",
            "  8% 115/1363 [00:15<01:22, 15.16it/s]\u001b[A\n",
            "  9% 117/1363 [00:15<01:20, 15.39it/s]\u001b[A\n",
            "  9% 119/1363 [00:15<01:18, 15.86it/s]\u001b[A\n",
            "  9% 121/1363 [00:15<01:17, 16.01it/s]\u001b[A\n",
            "  9% 123/1363 [00:16<01:18, 15.84it/s]\u001b[A\n",
            "  9% 125/1363 [00:16<01:18, 15.78it/s]\u001b[A\n",
            "  9% 127/1363 [00:16<01:14, 16.54it/s]\u001b[A\n",
            "  9% 129/1363 [00:16<01:18, 15.79it/s]\u001b[A\n",
            " 10% 131/1363 [00:16<01:19, 15.57it/s]\u001b[A\n",
            " 10% 133/1363 [00:16<01:16, 16.00it/s]\u001b[A\n",
            " 10% 135/1363 [00:16<01:18, 15.72it/s]\u001b[A\n",
            " 10% 137/1363 [00:17<01:16, 15.94it/s]\u001b[A\n",
            " 10% 139/1363 [00:17<01:16, 15.92it/s]\u001b[A\n",
            " 10% 141/1363 [00:17<01:17, 15.83it/s]\u001b[A\n",
            " 10% 143/1363 [00:17<01:24, 14.52it/s]\u001b[A2025-10-04 09:10:26,154 - ERROR - STDERR - \n",
            "2025-10-04 09:10:26,169 - ERROR - STDERR - model.safetensors:  60%|#####9    | 797M/1.33G [00:21<00:19, 27.2MB/s]\n",
            "\n",
            " 11% 145/1363 [00:17<01:44, 11.63it/s]\u001b[A2025-10-04 09:10:26,388 - ERROR - STDERR - \n",
            "2025-10-04 09:10:26,389 - ERROR - STDERR - model.safetensors:  65%|######4   | 864M/1.33G [00:21<00:12, 37.9MB/s]\n",
            "\n",
            " 11% 147/1363 [00:17<01:44, 11.61it/s]\u001b[A\n",
            " 11% 149/1363 [00:18<01:41, 12.00it/s]\u001b[A\n",
            " 11% 151/1363 [00:18<01:45, 11.54it/s]\u001b[A\n",
            " 11% 153/1363 [00:18<01:36, 12.53it/s]\u001b[A\n",
            " 11% 155/1363 [00:18<01:32, 13.04it/s]\u001b[A\n",
            " 12% 157/1363 [00:18<01:29, 13.42it/s]\u001b[A2025-10-04 09:10:27,306 - ERROR - STDERR - \n",
            "2025-10-04 09:10:27,309 - ERROR - STDERR - model.safetensors:  70%|######9   | 931M/1.33G [00:22<00:09, 44.5MB/s]\n",
            "\n",
            " 12% 159/1363 [00:18<01:29, 13.41it/s]\u001b[A\n",
            " 12% 161/1363 [00:18<01:25, 14.09it/s]\u001b[A\n",
            " 12% 163/1363 [00:18<01:20, 14.88it/s]\u001b[A\n",
            " 12% 165/1363 [00:19<01:17, 15.40it/s]\u001b[A\n",
            " 12% 167/1363 [00:19<01:19, 15.04it/s]\u001b[A\n",
            " 12% 169/1363 [00:19<01:18, 15.16it/s]\u001b[A2025-10-04 09:10:28,168 - ERROR - STDERR - \n",
            "2025-10-04 09:10:28,169 - ERROR - STDERR - model.safetensors:  75%|#######4  | 998M/1.33G [00:23<00:06, 51.2MB/s]\n",
            "\n",
            " 13% 171/1363 [00:19<01:19, 15.03it/s]\u001b[A\n",
            " 13% 173/1363 [00:19<01:20, 14.81it/s]\u001b[A\n",
            " 13% 175/1363 [00:19<01:19, 14.88it/s]\u001b[A\n",
            " 13% 177/1363 [00:19<01:20, 14.79it/s]\u001b[A\n",
            " 13% 179/1363 [00:20<01:17, 15.31it/s]\u001b[A\n",
            " 13% 181/1363 [00:20<01:17, 15.33it/s]\u001b[A\n",
            " 13% 183/1363 [00:20<01:14, 15.94it/s]\u001b[A\n",
            " 14% 185/1363 [00:20<01:17, 15.30it/s]\u001b[A\n",
            " 14% 187/1363 [00:20<01:17, 15.27it/s]\u001b[A\n",
            " 14% 189/1363 [00:20<01:15, 15.62it/s]\u001b[A\n",
            " 14% 191/1363 [00:20<01:14, 15.73it/s]\u001b[A\n",
            " 14% 193/1363 [00:20<01:13, 15.88it/s]\u001b[A\n",
            " 14% 195/1363 [00:21<01:18, 14.80it/s]\u001b[A\n",
            " 14% 197/1363 [00:21<01:24, 13.80it/s]\u001b[A\n",
            " 15% 199/1363 [00:21<01:27, 13.33it/s]\u001b[A\n",
            " 15% 201/1363 [00:21<01:30, 12.89it/s]\u001b[A2025-10-04 09:10:30,328 - ERROR - STDERR - \n",
            "2025-10-04 09:10:30,328 - ERROR - STDERR - model.safetensors:  80%|#######9  | 1.06G/1.33G [00:25<00:06, 42.8MB/s]\n",
            "\n",
            " 15% 203/1363 [00:21<01:37, 11.93it/s]\u001b[A2025-10-04 09:10:30,791 - ERROR - STDERR - \n",
            "2025-10-04 09:10:30,793 - ERROR - STDERR - model.safetensors:  85%|########4 | 1.13G/1.33G [00:26<00:03, 54.3MB/s]\n",
            "\n",
            " 15% 205/1363 [00:22<02:03,  9.35it/s]\u001b[A\n",
            " 15% 207/1363 [00:22<02:18,  8.35it/s]\u001b[A\n",
            " 15% 208/1363 [00:22<02:22,  8.11it/s]\u001b[A2025-10-04 09:10:31,281 - ERROR - STDERR - \n",
            "2025-10-04 09:10:31,287 - ERROR - STDERR - model.safetensors:  90%|########9 | 1.20G/1.33G [00:26<00:02, 66.4MB/s]\n",
            "\n",
            " 15% 209/1363 [00:22<02:23,  8.03it/s]\u001b[A\n",
            " 15% 210/1363 [00:22<02:29,  7.73it/s]\u001b[A2025-10-04 09:10:31,653 - ERROR - STDERR - \n",
            "2025-10-04 09:10:31,654 - ERROR - STDERR - model.safetensors:  95%|#########4| 1.27G/1.33G [00:26<00:00, 82.0MB/s]\n",
            "\n",
            " 16% 212/1363 [00:23<02:12,  8.71it/s]\u001b[A\n",
            " 16% 214/1363 [00:23<01:53, 10.11it/s]\u001b[A\n",
            " 16% 216/1363 [00:23<01:57,  9.75it/s]\u001b[A2025-10-04 09:10:32,163 - ERROR - STDERR - \n",
            "2025-10-04 09:10:32,165 - ERROR - STDERR - model.safetensors: 100%|##########| 1.33G/1.33G [00:27<00:00, 92.5MB/s]\n",
            "2025-10-04 09:10:32,168 - ERROR - STDERR - \n",
            "2025-10-04 09:10:32,171 - ERROR - STDERR - model.safetensors: 100%|##########| 1.33G/1.33G [00:27<00:00, 48.6MB/s]\n",
            "\n",
            " 16% 218/1363 [00:23<01:50, 10.39it/s]\u001b[A\n",
            " 16% 220/1363 [00:23<01:38, 11.58it/s]\u001b[A\n",
            " 16% 222/1363 [00:23<01:30, 12.57it/s]\u001b[A\n",
            " 16% 224/1363 [00:23<01:25, 13.29it/s]\u001b[A\n",
            " 17% 226/1363 [00:24<01:28, 12.89it/s]\u001b[A\n",
            " 17% 228/1363 [00:24<01:26, 13.08it/s]\u001b[A\n",
            " 17% 230/1363 [00:24<01:21, 13.94it/s]\u001b[A\n",
            " 17% 232/1363 [00:24<01:21, 13.89it/s]\u001b[A\n",
            " 17% 234/1363 [00:24<01:23, 13.57it/s]\u001b[A\n",
            " 17% 236/1363 [00:24<01:16, 14.71it/s]\u001b[A\n",
            " 17% 238/1363 [00:24<01:16, 14.65it/s]\u001b[A\n",
            " 18% 240/1363 [00:25<01:17, 14.57it/s]\u001b[A\n",
            " 18% 242/1363 [00:25<01:17, 14.53it/s]\u001b[A\n",
            " 18% 244/1363 [00:25<01:16, 14.60it/s]\u001b[A\n",
            " 18% 246/1363 [00:25<01:12, 15.33it/s]\u001b[A\n",
            " 18% 248/1363 [00:25<01:16, 14.66it/s]\u001b[A\n",
            " 18% 250/1363 [00:25<01:17, 14.35it/s]\u001b[A\n",
            " 18% 252/1363 [00:25<01:21, 13.71it/s]\u001b[A\n",
            " 19% 254/1363 [00:26<01:19, 14.00it/s]\u001b[A\n",
            " 19% 256/1363 [00:26<01:14, 14.84it/s]\u001b[A\n",
            " 19% 258/1363 [00:26<01:11, 15.51it/s]\u001b[A\n",
            " 19% 260/1363 [00:26<01:10, 15.73it/s]\u001b[A\n",
            " 19% 262/1363 [00:26<01:07, 16.23it/s]\u001b[A\n",
            " 19% 264/1363 [00:26<01:04, 17.02it/s]\u001b[A\n",
            " 20% 266/1363 [00:26<01:04, 17.09it/s]\u001b[A\n",
            " 20% 268/1363 [00:26<01:05, 16.62it/s]\u001b[A\n",
            " 20% 270/1363 [00:26<01:05, 16.74it/s]\u001b[A\n",
            " 20% 272/1363 [00:27<01:05, 16.71it/s]\u001b[A\n",
            " 20% 274/1363 [00:27<01:07, 16.21it/s]\u001b[A\n",
            " 20% 276/1363 [00:27<01:04, 16.90it/s]\u001b[A\n",
            " 20% 278/1363 [00:27<01:03, 17.17it/s]\u001b[A\n",
            " 21% 280/1363 [00:27<01:06, 16.27it/s]\u001b[A\n",
            " 21% 282/1363 [00:27<01:05, 16.46it/s]\u001b[A\n",
            " 21% 284/1363 [00:27<01:06, 16.19it/s]\u001b[A\n",
            " 21% 286/1363 [00:27<01:04, 16.73it/s]\u001b[A\n",
            " 21% 288/1363 [00:28<01:09, 15.44it/s]\u001b[A\n",
            " 21% 290/1363 [00:28<01:10, 15.19it/s]\u001b[A\n",
            " 21% 292/1363 [00:28<01:10, 15.14it/s]\u001b[A\n",
            " 22% 294/1363 [00:28<01:11, 15.02it/s]\u001b[A\n",
            " 22% 296/1363 [00:28<01:09, 15.29it/s]\u001b[A\n",
            " 22% 298/1363 [00:28<01:08, 15.46it/s]\u001b[A\n",
            " 22% 300/1363 [00:28<01:06, 15.97it/s]\u001b[A\n",
            " 22% 302/1363 [00:28<01:08, 15.40it/s]\u001b[A\n",
            " 22% 304/1363 [00:29<01:10, 14.92it/s]\u001b[A\n",
            " 22% 306/1363 [00:29<01:07, 15.56it/s]\u001b[A\n",
            " 23% 308/1363 [00:29<01:10, 14.92it/s]\u001b[A\n",
            " 23% 310/1363 [00:29<01:11, 14.64it/s]\u001b[A\n",
            " 23% 312/1363 [00:29<01:08, 15.28it/s]\u001b[A\n",
            " 23% 314/1363 [00:29<01:07, 15.56it/s]\u001b[A\n",
            " 23% 316/1363 [00:29<01:05, 15.94it/s]\u001b[A\n",
            " 23% 318/1363 [00:30<01:09, 15.14it/s]\u001b[A\n",
            " 23% 320/1363 [00:30<01:07, 15.37it/s]\u001b[A\n",
            " 24% 322/1363 [00:30<01:08, 15.24it/s]\u001b[A\n",
            " 24% 324/1363 [00:30<01:09, 14.99it/s]\u001b[A\n",
            " 24% 326/1363 [00:30<01:11, 14.50it/s]\u001b[A\n",
            " 24% 328/1363 [00:30<01:10, 14.66it/s]\u001b[A\n",
            " 24% 330/1363 [00:30<01:05, 15.68it/s]\u001b[A\n",
            " 24% 332/1363 [00:30<01:02, 16.47it/s]\u001b[A\n",
            " 25% 334/1363 [00:31<01:04, 15.84it/s]\u001b[A\n",
            " 25% 337/1363 [00:31<01:01, 16.73it/s]\u001b[A\n",
            " 25% 339/1363 [00:31<01:03, 16.23it/s]\u001b[A\n",
            " 25% 341/1363 [00:31<01:02, 16.28it/s]\u001b[A\n",
            " 25% 343/1363 [00:31<01:04, 15.91it/s]\u001b[A\n",
            " 25% 345/1363 [00:31<01:06, 15.21it/s]\u001b[A\n",
            " 25% 347/1363 [00:31<01:06, 15.21it/s]\u001b[A\n",
            " 26% 349/1363 [00:32<01:05, 15.38it/s]\u001b[A\n",
            " 26% 351/1363 [00:32<01:04, 15.72it/s]\u001b[A\n",
            " 26% 353/1363 [00:32<01:07, 15.02it/s]\u001b[A\n",
            " 26% 355/1363 [00:32<01:06, 15.08it/s]\u001b[A\n",
            " 26% 357/1363 [00:32<01:04, 15.68it/s]\u001b[A\n",
            " 26% 359/1363 [00:32<01:06, 15.07it/s]\u001b[A\n",
            " 26% 361/1363 [00:32<01:08, 14.68it/s]\u001b[A\n",
            " 27% 363/1363 [00:32<01:06, 15.13it/s]\u001b[A\n",
            " 27% 365/1363 [00:33<01:05, 15.34it/s]\u001b[A\n",
            " 27% 367/1363 [00:33<01:06, 14.90it/s]\u001b[A\n",
            " 27% 369/1363 [00:33<01:05, 15.19it/s]\u001b[A\n",
            " 27% 371/1363 [00:33<01:02, 15.85it/s]\u001b[A\n",
            " 27% 373/1363 [00:33<01:04, 15.31it/s]\u001b[A\n",
            " 28% 375/1363 [00:33<01:04, 15.40it/s]\u001b[A\n",
            " 28% 377/1363 [00:33<01:02, 15.72it/s]\u001b[A\n",
            " 28% 379/1363 [00:33<01:02, 15.78it/s]\u001b[A\n",
            " 28% 381/1363 [00:34<01:00, 16.14it/s]\u001b[A\n",
            " 28% 383/1363 [00:34<01:00, 16.18it/s]\u001b[A\n",
            " 28% 385/1363 [00:34<01:01, 15.80it/s]\u001b[A\n",
            " 28% 387/1363 [00:34<00:59, 16.32it/s]\u001b[A\n",
            " 29% 389/1363 [00:34<01:01, 15.78it/s]\u001b[A\n",
            " 29% 391/1363 [00:34<00:58, 16.63it/s]\u001b[A\n",
            " 29% 393/1363 [00:34<01:00, 15.95it/s]\u001b[A\n",
            " 29% 395/1363 [00:34<00:59, 16.37it/s]\u001b[A\n",
            " 29% 397/1363 [00:35<01:03, 15.17it/s]\u001b[A\n",
            " 29% 399/1363 [00:35<01:00, 15.98it/s]\u001b[A\n",
            " 29% 401/1363 [00:35<01:00, 15.81it/s]\u001b[A\n",
            " 30% 404/1363 [00:35<00:56, 16.99it/s]\u001b[A\n",
            " 30% 406/1363 [00:35<00:55, 17.28it/s]\u001b[A\n",
            " 30% 408/1363 [00:35<00:57, 16.56it/s]\u001b[A\n",
            " 30% 410/1363 [00:35<00:56, 16.80it/s]\u001b[A\n",
            " 30% 412/1363 [00:36<00:59, 16.03it/s]\u001b[A\n",
            " 30% 414/1363 [00:36<00:58, 16.10it/s]\u001b[A\n",
            " 31% 416/1363 [00:36<01:00, 15.74it/s]\u001b[A\n",
            " 31% 418/1363 [00:36<01:01, 15.48it/s]\u001b[A\n",
            " 31% 420/1363 [00:36<01:01, 15.29it/s]\u001b[A\n",
            " 31% 422/1363 [00:36<01:02, 15.02it/s]\u001b[A\n",
            " 31% 424/1363 [00:36<00:58, 16.13it/s]\u001b[A\n",
            " 31% 426/1363 [00:36<00:56, 16.71it/s]\u001b[A\n",
            " 31% 428/1363 [00:37<00:56, 16.49it/s]\u001b[A\n",
            " 32% 430/1363 [00:37<00:57, 16.25it/s]\u001b[A\n",
            " 32% 432/1363 [00:37<01:00, 15.37it/s]\u001b[A\n",
            " 32% 434/1363 [00:37<00:59, 15.73it/s]\u001b[A\n",
            " 32% 436/1363 [00:37<01:03, 14.59it/s]\u001b[A\n",
            " 32% 438/1363 [00:37<01:04, 14.28it/s]\u001b[A\n",
            " 32% 440/1363 [00:37<01:01, 15.03it/s]\u001b[A\n",
            " 32% 442/1363 [00:37<01:00, 15.10it/s]\u001b[A\n",
            " 33% 444/1363 [00:38<00:58, 15.80it/s]\u001b[A\n",
            " 33% 446/1363 [00:38<00:54, 16.67it/s]\u001b[A\n",
            " 33% 448/1363 [00:38<00:58, 15.65it/s]\u001b[A\n",
            " 33% 450/1363 [00:38<00:56, 16.19it/s]\u001b[A\n",
            " 33% 452/1363 [00:38<00:57, 15.84it/s]\u001b[A\n",
            " 33% 454/1363 [00:38<00:58, 15.62it/s]\u001b[A\n",
            " 33% 456/1363 [00:38<00:58, 15.41it/s]\u001b[A\n",
            " 34% 458/1363 [00:38<00:58, 15.39it/s]\u001b[A\n",
            " 34% 460/1363 [00:39<00:57, 15.68it/s]\u001b[A\n",
            " 34% 462/1363 [00:39<00:59, 15.23it/s]\u001b[A\n",
            " 34% 464/1363 [00:39<00:58, 15.33it/s]\u001b[A\n",
            " 34% 466/1363 [00:39<00:57, 15.50it/s]\u001b[A\n",
            " 34% 468/1363 [00:39<00:59, 14.95it/s]\u001b[A\n",
            " 34% 470/1363 [00:39<01:00, 14.67it/s]\u001b[A\n",
            " 35% 472/1363 [00:39<01:00, 14.65it/s]\u001b[A\n",
            " 35% 474/1363 [00:40<00:57, 15.44it/s]\u001b[A\n",
            " 35% 476/1363 [00:40<00:58, 15.27it/s]\u001b[A\n",
            " 35% 478/1363 [00:40<00:57, 15.37it/s]\u001b[A\n",
            " 35% 480/1363 [00:40<00:54, 16.25it/s]\u001b[A\n",
            " 35% 482/1363 [00:40<00:55, 15.89it/s]\u001b[A\n",
            " 36% 484/1363 [00:40<00:56, 15.50it/s]\u001b[A\n",
            " 36% 486/1363 [00:40<00:54, 16.19it/s]\u001b[A\n",
            " 36% 488/1363 [00:40<00:57, 15.14it/s]\u001b[A\n",
            " 36% 490/1363 [00:41<00:57, 15.15it/s]\u001b[A\n",
            " 36% 492/1363 [00:41<00:57, 15.19it/s]\u001b[A\n",
            " 36% 494/1363 [00:41<00:59, 14.68it/s]\u001b[A\n",
            " 36% 496/1363 [00:41<00:57, 15.10it/s]\u001b[A\n",
            " 37% 498/1363 [00:41<00:58, 14.73it/s]\u001b[A\n",
            " 37% 500/1363 [00:41<00:58, 14.87it/s]\u001b[A\n",
            " 37% 502/1363 [00:41<00:58, 14.74it/s]\u001b[A\n",
            " 37% 504/1363 [00:41<00:57, 14.98it/s]\u001b[A\n",
            " 37% 506/1363 [00:42<00:54, 15.69it/s]\u001b[A\n",
            " 37% 508/1363 [00:42<00:52, 16.30it/s]\u001b[A\n",
            " 37% 510/1363 [00:42<00:54, 15.54it/s]\u001b[A\n",
            " 38% 512/1363 [00:42<00:55, 15.35it/s]\u001b[A\n",
            " 38% 514/1363 [00:42<00:54, 15.58it/s]\u001b[A\n",
            " 38% 516/1363 [00:42<00:55, 15.20it/s]\u001b[A\n",
            " 38% 518/1363 [00:42<00:53, 15.73it/s]\u001b[A\n",
            " 38% 520/1363 [00:42<00:50, 16.56it/s]\u001b[A\n",
            " 38% 522/1363 [00:43<00:52, 16.08it/s]\u001b[A\n",
            " 38% 524/1363 [00:43<00:52, 15.99it/s]\u001b[A\n",
            " 39% 526/1363 [00:43<00:51, 16.35it/s]\u001b[A\n",
            " 39% 528/1363 [00:43<00:51, 16.27it/s]\u001b[A\n",
            " 39% 530/1363 [00:43<00:50, 16.50it/s]\u001b[A\n",
            " 39% 532/1363 [00:43<00:52, 15.90it/s]\u001b[A\n",
            " 39% 534/1363 [00:43<00:51, 16.09it/s]\u001b[A\n",
            " 39% 536/1363 [00:44<00:54, 15.18it/s]\u001b[A\n",
            " 39% 538/1363 [00:44<00:53, 15.33it/s]\u001b[A\n",
            " 40% 540/1363 [00:44<00:53, 15.42it/s]\u001b[A\n",
            " 40% 542/1363 [00:44<00:52, 15.68it/s]\u001b[A\n",
            " 40% 544/1363 [00:44<00:53, 15.35it/s]\u001b[A\n",
            " 40% 546/1363 [00:44<00:52, 15.65it/s]\u001b[A\n",
            " 40% 548/1363 [00:44<00:51, 15.92it/s]\u001b[A\n",
            " 40% 550/1363 [00:44<00:50, 16.22it/s]\u001b[A\n",
            " 40% 552/1363 [00:44<00:48, 16.60it/s]\u001b[A\n",
            " 41% 554/1363 [00:45<00:52, 15.52it/s]\u001b[A\n",
            " 41% 556/1363 [00:45<00:52, 15.39it/s]\u001b[A\n",
            " 41% 558/1363 [00:45<00:53, 15.09it/s]\u001b[A\n",
            " 41% 560/1363 [00:45<00:50, 15.79it/s]\u001b[A\n",
            " 41% 562/1363 [00:45<00:52, 15.36it/s]\u001b[A\n",
            " 41% 564/1363 [00:45<00:53, 14.87it/s]\u001b[A\n",
            " 42% 566/1363 [00:45<00:53, 14.82it/s]\u001b[A\n",
            " 42% 568/1363 [00:46<00:54, 14.59it/s]\u001b[A\n",
            " 42% 570/1363 [00:46<00:53, 14.95it/s]\u001b[A\n",
            " 42% 572/1363 [00:46<00:54, 14.44it/s]\u001b[A\n",
            " 42% 574/1363 [00:46<00:53, 14.78it/s]\u001b[A\n",
            " 42% 576/1363 [00:46<00:53, 14.64it/s]\u001b[A\n",
            " 42% 578/1363 [00:46<00:54, 14.53it/s]\u001b[A\n",
            " 43% 580/1363 [00:46<00:53, 14.65it/s]\u001b[A\n",
            " 43% 582/1363 [00:47<00:52, 14.87it/s]\u001b[A\n",
            " 43% 584/1363 [00:47<00:51, 15.06it/s]\u001b[A\n",
            " 43% 586/1363 [00:47<00:54, 14.18it/s]\u001b[A\n",
            " 43% 588/1363 [00:47<00:58, 13.28it/s]\u001b[A\n",
            " 43% 590/1363 [00:47<00:55, 13.85it/s]\u001b[A\n",
            " 43% 592/1363 [00:47<00:54, 14.27it/s]\u001b[A\n",
            " 44% 594/1363 [00:47<00:53, 14.39it/s]\u001b[A\n",
            " 44% 596/1363 [00:48<00:52, 14.54it/s]\u001b[A\n",
            " 44% 598/1363 [00:48<00:52, 14.66it/s]\u001b[A\n",
            " 44% 600/1363 [00:48<00:50, 15.09it/s]\u001b[A\n",
            " 44% 602/1363 [00:48<00:49, 15.23it/s]\u001b[A\n",
            " 44% 604/1363 [00:48<00:47, 15.94it/s]\u001b[A\n",
            " 44% 606/1363 [00:48<00:48, 15.49it/s]\u001b[A\n",
            " 45% 608/1363 [00:48<00:47, 15.86it/s]\u001b[A\n",
            " 45% 610/1363 [00:48<00:46, 16.19it/s]\u001b[A\n",
            " 45% 612/1363 [00:49<00:50, 14.88it/s]\u001b[A\n",
            " 45% 614/1363 [00:49<00:51, 14.56it/s]\u001b[A\n",
            " 45% 616/1363 [00:49<00:49, 14.94it/s]\u001b[A\n",
            " 45% 618/1363 [00:49<00:50, 14.77it/s]\u001b[A\n",
            " 45% 620/1363 [00:49<00:49, 14.94it/s]\u001b[A\n",
            " 46% 622/1363 [00:49<00:49, 15.00it/s]\u001b[A\n",
            " 46% 624/1363 [00:49<00:48, 15.33it/s]\u001b[A\n",
            " 46% 626/1363 [00:49<00:46, 15.70it/s]\u001b[A\n",
            " 46% 628/1363 [00:50<00:48, 15.02it/s]\u001b[A\n",
            " 46% 630/1363 [00:50<00:47, 15.40it/s]\u001b[A\n",
            " 46% 632/1363 [00:50<00:46, 15.76it/s]\u001b[A\n",
            " 47% 634/1363 [00:50<00:45, 15.93it/s]\u001b[A\n",
            " 47% 636/1363 [00:50<00:43, 16.80it/s]\u001b[A\n",
            " 47% 638/1363 [00:50<00:46, 15.67it/s]\u001b[A\n",
            " 47% 640/1363 [00:50<00:46, 15.42it/s]\u001b[A\n",
            " 47% 642/1363 [00:51<00:49, 14.67it/s]\u001b[A\n",
            " 47% 644/1363 [00:51<00:49, 14.55it/s]\u001b[A\n",
            " 47% 646/1363 [00:51<00:48, 14.66it/s]\u001b[A\n",
            " 48% 648/1363 [00:51<00:47, 14.93it/s]\u001b[A\n",
            " 48% 650/1363 [00:51<00:49, 14.33it/s]\u001b[A\n",
            " 48% 652/1363 [00:51<00:48, 14.62it/s]\u001b[A\n",
            " 48% 654/1363 [00:51<00:49, 14.36it/s]\u001b[A\n",
            " 48% 656/1363 [00:51<00:49, 14.26it/s]\u001b[A\n",
            " 48% 658/1363 [00:52<00:49, 14.16it/s]\u001b[A\n",
            " 48% 660/1363 [00:52<00:45, 15.31it/s]\u001b[A\n",
            " 49% 662/1363 [00:52<00:46, 14.99it/s]\u001b[A\n",
            " 49% 664/1363 [00:52<00:43, 16.17it/s]\u001b[A\n",
            " 49% 666/1363 [00:52<00:44, 15.70it/s]\u001b[A\n",
            " 49% 668/1363 [00:52<00:46, 14.92it/s]\u001b[A\n",
            " 49% 670/1363 [00:52<00:44, 15.42it/s]\u001b[A\n",
            " 49% 672/1363 [00:53<00:46, 14.71it/s]\u001b[A\n",
            " 49% 674/1363 [00:53<00:47, 14.44it/s]\u001b[A\n",
            " 50% 676/1363 [00:53<00:47, 14.45it/s]\u001b[A\n",
            " 50% 678/1363 [00:53<00:45, 14.93it/s]\u001b[A\n",
            " 50% 680/1363 [00:53<00:47, 14.34it/s]\u001b[A\n",
            " 50% 682/1363 [00:53<00:47, 14.20it/s]\u001b[A\n",
            " 50% 684/1363 [00:53<00:46, 14.51it/s]\u001b[A\n",
            " 50% 686/1363 [00:54<00:45, 14.77it/s]\u001b[A\n",
            " 50% 688/1363 [00:54<00:43, 15.42it/s]\u001b[A\n",
            " 51% 690/1363 [00:54<00:45, 14.72it/s]\u001b[A\n",
            " 51% 692/1363 [00:54<00:45, 14.71it/s]\u001b[A\n",
            " 51% 694/1363 [00:54<00:43, 15.37it/s]\u001b[A\n",
            " 51% 696/1363 [00:54<00:41, 16.23it/s]\u001b[A\n",
            " 51% 698/1363 [00:54<00:43, 15.46it/s]\u001b[A\n",
            " 51% 700/1363 [00:54<00:43, 15.40it/s]\u001b[A\n",
            " 52% 702/1363 [00:55<00:44, 15.00it/s]\u001b[A\n",
            " 52% 704/1363 [00:55<00:43, 15.25it/s]\u001b[A\n",
            " 52% 706/1363 [00:55<00:42, 15.43it/s]\u001b[A\n",
            " 52% 708/1363 [00:55<00:41, 15.78it/s]\u001b[A\n",
            " 52% 710/1363 [00:55<00:42, 15.31it/s]\u001b[A\n",
            " 52% 712/1363 [00:55<00:40, 16.16it/s]\u001b[A\n",
            " 52% 714/1363 [00:55<00:40, 16.02it/s]\u001b[A\n",
            " 53% 716/1363 [00:55<00:41, 15.52it/s]\u001b[A\n",
            " 53% 718/1363 [00:56<00:41, 15.38it/s]\u001b[A\n",
            " 53% 720/1363 [00:56<00:40, 15.81it/s]\u001b[A\n",
            " 53% 722/1363 [00:56<00:41, 15.57it/s]\u001b[A\n",
            " 53% 724/1363 [00:56<00:43, 14.85it/s]\u001b[A\n",
            " 53% 726/1363 [00:56<00:41, 15.52it/s]\u001b[A\n",
            " 53% 728/1363 [00:56<00:40, 15.53it/s]\u001b[A\n",
            " 54% 730/1363 [00:56<00:41, 15.09it/s]\u001b[A\n",
            " 54% 732/1363 [00:56<00:42, 14.99it/s]\u001b[A\n",
            " 54% 734/1363 [00:57<00:39, 15.84it/s]\u001b[A\n",
            " 54% 736/1363 [00:57<00:39, 15.74it/s]\u001b[A\n",
            " 54% 738/1363 [00:57<00:40, 15.28it/s]\u001b[A\n",
            " 54% 740/1363 [00:57<00:41, 15.14it/s]\u001b[A\n",
            " 54% 742/1363 [00:57<00:41, 14.99it/s]\u001b[A\n",
            " 55% 744/1363 [00:57<00:42, 14.47it/s]\u001b[A\n",
            " 55% 746/1363 [00:57<00:42, 14.50it/s]\u001b[A\n",
            " 55% 748/1363 [00:58<00:40, 15.04it/s]\u001b[A\n",
            " 55% 750/1363 [00:58<00:39, 15.67it/s]\u001b[A\n",
            " 55% 752/1363 [00:58<00:40, 15.18it/s]\u001b[A\n",
            " 55% 754/1363 [00:58<00:40, 14.91it/s]\u001b[A\n",
            " 55% 756/1363 [00:58<00:40, 15.06it/s]\u001b[A\n",
            " 56% 758/1363 [00:58<00:39, 15.13it/s]\u001b[A\n",
            " 56% 760/1363 [00:58<00:39, 15.20it/s]\u001b[A\n",
            " 56% 762/1363 [00:58<00:39, 15.27it/s]\u001b[A\n",
            " 56% 765/1363 [00:59<00:36, 16.34it/s]\u001b[A\n",
            " 56% 767/1363 [00:59<00:36, 16.33it/s]\u001b[A\n",
            " 56% 769/1363 [00:59<00:37, 16.05it/s]\u001b[A\n",
            " 57% 771/1363 [00:59<00:35, 16.61it/s]\u001b[A\n",
            " 57% 773/1363 [00:59<00:35, 16.82it/s]\u001b[A\n",
            " 57% 775/1363 [00:59<00:36, 16.08it/s]\u001b[A\n",
            " 57% 777/1363 [00:59<00:39, 14.73it/s]\u001b[A\n",
            " 57% 779/1363 [01:00<00:39, 14.86it/s]\u001b[A\n",
            " 57% 781/1363 [01:00<00:39, 14.83it/s]\u001b[A\n",
            " 57% 783/1363 [01:00<00:37, 15.35it/s]\u001b[A\n",
            " 58% 785/1363 [01:00<00:37, 15.52it/s]\u001b[A\n",
            " 58% 787/1363 [01:00<00:37, 15.18it/s]\u001b[A\n",
            " 58% 789/1363 [01:00<00:38, 14.92it/s]\u001b[A\n",
            " 58% 791/1363 [01:00<00:35, 15.91it/s]\u001b[A\n",
            " 58% 793/1363 [01:00<00:34, 16.38it/s]\u001b[A\n",
            " 58% 795/1363 [01:01<00:35, 16.20it/s]\u001b[A\n",
            " 58% 797/1363 [01:01<00:32, 17.16it/s]\u001b[A\n",
            " 59% 799/1363 [01:01<00:35, 15.68it/s]\u001b[A\n",
            " 59% 801/1363 [01:01<00:35, 15.68it/s]\u001b[A\n",
            " 59% 803/1363 [01:01<00:36, 15.48it/s]\u001b[A\n",
            " 59% 805/1363 [01:01<00:36, 15.18it/s]\u001b[A\n",
            " 59% 807/1363 [01:01<00:36, 15.43it/s]\u001b[A\n",
            " 59% 809/1363 [01:01<00:34, 16.22it/s]\u001b[A\n",
            " 60% 811/1363 [01:02<00:33, 16.55it/s]\u001b[A\n",
            " 60% 813/1363 [01:02<00:33, 16.52it/s]\u001b[A\n",
            " 60% 815/1363 [01:02<00:35, 15.39it/s]\u001b[A\n",
            " 60% 818/1363 [01:02<00:34, 15.89it/s]\u001b[A\n",
            " 60% 820/1363 [01:02<00:34, 15.90it/s]\u001b[A\n",
            " 60% 822/1363 [01:02<00:34, 15.55it/s]\u001b[A\n",
            " 60% 824/1363 [01:02<00:33, 16.08it/s]\u001b[A\n",
            " 61% 826/1363 [01:02<00:32, 16.33it/s]\u001b[A\n",
            " 61% 828/1363 [01:03<00:34, 15.72it/s]\u001b[A\n",
            " 61% 830/1363 [01:03<00:33, 15.79it/s]\u001b[A\n",
            " 61% 832/1363 [01:03<00:32, 16.10it/s]\u001b[A\n",
            " 61% 834/1363 [01:03<00:34, 15.32it/s]\u001b[A\n",
            " 61% 836/1363 [01:03<00:35, 14.81it/s]\u001b[A\n",
            " 61% 838/1363 [01:03<00:37, 14.00it/s]\u001b[A\n",
            " 62% 840/1363 [01:03<00:37, 13.80it/s]\u001b[A\n",
            " 62% 842/1363 [01:04<00:35, 14.52it/s]\u001b[A\n",
            " 62% 844/1363 [01:04<00:34, 14.96it/s]\u001b[A\n",
            " 62% 846/1363 [01:04<00:33, 15.41it/s]\u001b[A\n",
            " 62% 848/1363 [01:04<00:34, 15.11it/s]\u001b[A\n",
            " 62% 850/1363 [01:04<00:34, 15.05it/s]\u001b[A\n",
            " 63% 852/1363 [01:04<00:33, 15.20it/s]\u001b[A\n",
            " 63% 854/1363 [01:04<00:35, 14.40it/s]\u001b[A\n",
            " 63% 856/1363 [01:05<00:33, 15.23it/s]\u001b[A\n",
            " 63% 858/1363 [01:05<00:32, 15.77it/s]\u001b[A\n",
            " 63% 860/1363 [01:05<00:32, 15.27it/s]\u001b[A\n",
            " 63% 862/1363 [01:05<00:34, 14.72it/s]\u001b[A\n",
            " 63% 864/1363 [01:05<00:33, 14.70it/s]\u001b[A\n",
            " 64% 866/1363 [01:05<00:33, 14.63it/s]\u001b[A\n",
            " 64% 868/1363 [01:05<00:35, 13.85it/s]\u001b[A\n",
            " 64% 870/1363 [01:06<00:36, 13.64it/s]\u001b[A\n",
            " 64% 872/1363 [01:06<00:35, 13.70it/s]\u001b[A\n",
            " 64% 874/1363 [01:06<00:35, 13.88it/s]\u001b[A\n",
            " 64% 876/1363 [01:06<00:35, 13.80it/s]\u001b[A\n",
            " 64% 878/1363 [01:06<00:35, 13.83it/s]\u001b[A\n",
            " 65% 880/1363 [01:06<00:35, 13.66it/s]\u001b[A\n",
            " 65% 882/1363 [01:06<00:35, 13.71it/s]\u001b[A\n",
            " 65% 884/1363 [01:07<00:35, 13.36it/s]\u001b[A\n",
            " 65% 886/1363 [01:07<00:34, 13.86it/s]\u001b[A\n",
            " 65% 888/1363 [01:07<00:34, 13.73it/s]\u001b[A\n",
            " 65% 890/1363 [01:07<00:34, 13.59it/s]\u001b[A\n",
            " 65% 892/1363 [01:07<00:32, 14.49it/s]\u001b[A\n",
            " 66% 895/1363 [01:07<00:28, 16.56it/s]\u001b[A\n",
            " 66% 897/1363 [01:07<00:29, 15.98it/s]\u001b[A\n",
            " 66% 899/1363 [01:07<00:28, 16.31it/s]\u001b[A\n",
            " 66% 901/1363 [01:08<00:26, 17.14it/s]\u001b[A\n",
            " 66% 903/1363 [01:08<00:27, 16.69it/s]\u001b[A\n",
            " 66% 905/1363 [01:08<00:28, 15.91it/s]\u001b[A\n",
            " 67% 907/1363 [01:08<00:29, 15.36it/s]\u001b[A\n",
            " 67% 909/1363 [01:08<00:29, 15.34it/s]\u001b[A\n",
            " 67% 911/1363 [01:08<00:28, 15.92it/s]\u001b[A\n",
            " 67% 913/1363 [01:08<00:28, 15.55it/s]\u001b[A\n",
            " 67% 915/1363 [01:08<00:28, 15.51it/s]\u001b[A\n",
            " 67% 917/1363 [01:09<00:28, 15.46it/s]\u001b[A\n",
            " 67% 919/1363 [01:09<00:28, 15.59it/s]\u001b[A\n",
            " 68% 921/1363 [01:09<00:28, 15.77it/s]\u001b[A\n",
            " 68% 923/1363 [01:09<00:27, 15.75it/s]\u001b[A\n",
            " 68% 925/1363 [01:09<00:27, 16.02it/s]\u001b[A\n",
            " 68% 927/1363 [01:09<00:28, 15.44it/s]\u001b[A\n",
            " 68% 929/1363 [01:09<00:28, 15.03it/s]\u001b[A\n",
            " 68% 931/1363 [01:10<00:28, 15.30it/s]\u001b[A\n",
            " 68% 933/1363 [01:10<00:26, 15.94it/s]\u001b[A\n",
            " 69% 935/1363 [01:10<00:25, 16.70it/s]\u001b[A\n",
            " 69% 937/1363 [01:10<00:25, 16.53it/s]\u001b[A\n",
            " 69% 939/1363 [01:10<00:26, 15.77it/s]\u001b[A\n",
            " 69% 941/1363 [01:10<00:26, 15.83it/s]\u001b[A\n",
            " 69% 943/1363 [01:10<00:26, 15.64it/s]\u001b[A\n",
            " 69% 945/1363 [01:10<00:26, 15.66it/s]\u001b[A\n",
            " 69% 947/1363 [01:11<00:25, 16.18it/s]\u001b[A\n",
            " 70% 949/1363 [01:11<00:26, 15.41it/s]\u001b[A\n",
            " 70% 951/1363 [01:11<00:25, 15.95it/s]\u001b[A\n",
            " 70% 953/1363 [01:11<00:26, 15.73it/s]\u001b[A\n",
            " 70% 955/1363 [01:11<00:25, 16.01it/s]\u001b[A\n",
            " 70% 957/1363 [01:11<00:24, 16.57it/s]\u001b[A\n",
            " 70% 959/1363 [01:11<00:26, 15.53it/s]\u001b[A\n",
            " 71% 961/1363 [01:11<00:25, 15.57it/s]\u001b[A\n",
            " 71% 963/1363 [01:12<00:24, 16.10it/s]\u001b[A\n",
            " 71% 965/1363 [01:12<00:24, 16.13it/s]\u001b[A\n",
            " 71% 967/1363 [01:12<00:23, 17.00it/s]\u001b[A\n",
            " 71% 969/1363 [01:12<00:22, 17.44it/s]\u001b[A\n",
            " 71% 971/1363 [01:12<00:23, 16.35it/s]\u001b[A\n",
            " 71% 973/1363 [01:12<00:25, 15.11it/s]\u001b[A\n",
            " 72% 975/1363 [01:12<00:25, 15.39it/s]\u001b[A\n",
            " 72% 977/1363 [01:12<00:25, 14.89it/s]\u001b[A\n",
            " 72% 979/1363 [01:13<00:27, 14.20it/s]\u001b[A\n",
            " 72% 981/1363 [01:13<00:26, 14.27it/s]\u001b[A\n",
            " 72% 983/1363 [01:13<00:26, 14.12it/s]\u001b[A\n",
            " 72% 985/1363 [01:13<00:27, 13.91it/s]\u001b[A\n",
            " 72% 987/1363 [01:13<00:25, 14.83it/s]\u001b[A\n",
            " 73% 989/1363 [01:13<00:24, 15.10it/s]\u001b[A\n",
            " 73% 991/1363 [01:13<00:24, 15.03it/s]\u001b[A\n",
            " 73% 993/1363 [01:14<00:25, 14.61it/s]\u001b[A\n",
            " 73% 995/1363 [01:14<00:24, 14.97it/s]\u001b[A\n",
            " 73% 997/1363 [01:14<00:25, 14.53it/s]\u001b[A\n",
            " 73% 999/1363 [01:14<00:24, 14.93it/s]\u001b[A\n",
            " 73% 1001/1363 [01:14<00:23, 15.60it/s]\u001b[A\n",
            " 74% 1003/1363 [01:14<00:23, 15.48it/s]\u001b[A\n",
            " 74% 1005/1363 [01:14<00:24, 14.61it/s]\u001b[A\n",
            " 74% 1007/1363 [01:14<00:24, 14.54it/s]\u001b[A\n",
            " 74% 1009/1363 [01:15<00:24, 14.35it/s]\u001b[A\n",
            " 74% 1011/1363 [01:15<00:24, 14.55it/s]\u001b[A\n",
            " 74% 1013/1363 [01:15<00:24, 14.20it/s]\u001b[A\n",
            " 74% 1015/1363 [01:15<00:24, 14.43it/s]\u001b[A\n",
            " 75% 1017/1363 [01:15<00:24, 14.29it/s]\u001b[A\n",
            " 75% 1019/1363 [01:15<00:22, 15.14it/s]\u001b[A\n",
            " 75% 1021/1363 [01:15<00:22, 15.24it/s]\u001b[A\n",
            " 75% 1023/1363 [01:16<00:22, 14.92it/s]\u001b[A\n",
            " 75% 1025/1363 [01:16<00:22, 14.74it/s]\u001b[A\n",
            " 75% 1027/1363 [01:16<00:21, 15.40it/s]\u001b[A\n",
            " 75% 1029/1363 [01:16<00:22, 14.93it/s]\u001b[A\n",
            " 76% 1031/1363 [01:16<00:20, 16.01it/s]\u001b[A\n",
            " 76% 1033/1363 [01:16<00:21, 15.19it/s]\u001b[A\n",
            " 76% 1035/1363 [01:16<00:21, 15.14it/s]\u001b[A\n",
            " 76% 1037/1363 [01:16<00:21, 15.15it/s]\u001b[A\n",
            " 76% 1039/1363 [01:17<00:20, 15.71it/s]\u001b[A\n",
            " 76% 1041/1363 [01:17<00:20, 15.37it/s]\u001b[A\n",
            " 77% 1043/1363 [01:17<00:20, 15.33it/s]\u001b[A\n",
            " 77% 1045/1363 [01:17<00:21, 14.80it/s]\u001b[A\n",
            " 77% 1047/1363 [01:17<00:21, 14.61it/s]\u001b[A\n",
            " 77% 1049/1363 [01:17<00:22, 13.98it/s]\u001b[A\n",
            " 77% 1051/1363 [01:17<00:21, 14.76it/s]\u001b[A\n",
            " 77% 1053/1363 [01:18<00:20, 14.91it/s]\u001b[A\n",
            " 77% 1055/1363 [01:18<00:20, 15.35it/s]\u001b[A\n",
            " 78% 1057/1363 [01:18<00:19, 15.89it/s]\u001b[A\n",
            " 78% 1059/1363 [01:18<00:20, 14.78it/s]\u001b[A\n",
            " 78% 1061/1363 [01:18<00:20, 14.66it/s]\u001b[A\n",
            " 78% 1063/1363 [01:18<00:21, 13.94it/s]\u001b[A\n",
            " 78% 1065/1363 [01:18<00:20, 14.33it/s]\u001b[A\n",
            " 78% 1067/1363 [01:18<00:19, 14.81it/s]\u001b[A\n",
            " 78% 1069/1363 [01:19<00:20, 14.39it/s]\u001b[A\n",
            " 79% 1071/1363 [01:19<00:19, 14.74it/s]\u001b[A\n",
            " 79% 1073/1363 [01:19<00:20, 14.27it/s]\u001b[A\n",
            " 79% 1075/1363 [01:19<00:20, 14.33it/s]\u001b[A\n",
            " 79% 1077/1363 [01:19<00:20, 14.07it/s]\u001b[A\n",
            " 79% 1079/1363 [01:19<00:20, 13.85it/s]\u001b[A\n",
            " 79% 1081/1363 [01:19<00:19, 14.23it/s]\u001b[A\n",
            " 79% 1083/1363 [01:20<00:20, 13.71it/s]\u001b[A\n",
            " 80% 1085/1363 [01:20<00:20, 13.62it/s]\u001b[A\n",
            " 80% 1087/1363 [01:20<00:20, 13.55it/s]\u001b[A\n",
            " 80% 1089/1363 [01:20<00:19, 13.93it/s]\u001b[A\n",
            " 80% 1091/1363 [01:20<00:20, 13.40it/s]\u001b[A\n",
            " 80% 1093/1363 [01:20<00:19, 13.51it/s]\u001b[A\n",
            " 80% 1095/1363 [01:20<00:18, 14.59it/s]\u001b[A\n",
            " 80% 1097/1363 [01:21<00:18, 14.68it/s]\u001b[A\n",
            " 81% 1099/1363 [01:21<00:17, 15.00it/s]\u001b[A\n",
            " 81% 1102/1363 [01:21<00:15, 16.43it/s]\u001b[A\n",
            " 81% 1104/1363 [01:21<00:16, 15.27it/s]\u001b[A\n",
            " 81% 1106/1363 [01:21<00:17, 14.89it/s]\u001b[A\n",
            " 81% 1108/1363 [01:21<00:16, 15.33it/s]\u001b[A\n",
            " 81% 1110/1363 [01:21<00:16, 15.38it/s]\u001b[A\n",
            " 82% 1112/1363 [01:22<00:16, 15.63it/s]\u001b[A\n",
            " 82% 1114/1363 [01:22<00:16, 14.97it/s]\u001b[A\n",
            " 82% 1116/1363 [01:22<00:16, 14.64it/s]\u001b[A\n",
            " 82% 1118/1363 [01:22<00:16, 14.45it/s]\u001b[A\n",
            " 82% 1120/1363 [01:22<00:16, 14.30it/s]\u001b[A\n",
            " 82% 1122/1363 [01:22<00:17, 14.15it/s]\u001b[A\n",
            " 82% 1124/1363 [01:22<00:16, 14.79it/s]\u001b[A\n",
            " 83% 1126/1363 [01:23<00:16, 14.52it/s]\u001b[A\n",
            " 83% 1128/1363 [01:23<00:15, 15.45it/s]\u001b[A\n",
            " 83% 1130/1363 [01:23<00:14, 15.78it/s]\u001b[A\n",
            " 83% 1132/1363 [01:23<00:15, 14.60it/s]\u001b[A\n",
            " 83% 1134/1363 [01:23<00:15, 14.68it/s]\u001b[A\n",
            " 83% 1136/1363 [01:23<00:16, 14.10it/s]\u001b[A\n",
            " 83% 1138/1363 [01:23<00:15, 14.71it/s]\u001b[A\n",
            " 84% 1140/1363 [01:24<00:15, 14.40it/s]\u001b[A\n",
            " 84% 1142/1363 [01:24<00:15, 14.29it/s]\u001b[A\n",
            " 84% 1144/1363 [01:24<00:15, 13.84it/s]\u001b[A\n",
            " 84% 1146/1363 [01:24<00:15, 13.81it/s]\u001b[A\n",
            " 84% 1148/1363 [01:24<00:14, 14.81it/s]\u001b[A\n",
            " 84% 1150/1363 [01:24<00:14, 14.23it/s]\u001b[A\n",
            " 85% 1152/1363 [01:24<00:14, 14.53it/s]\u001b[A\n",
            " 85% 1154/1363 [01:25<00:14, 14.31it/s]\u001b[A\n",
            " 85% 1156/1363 [01:25<00:13, 14.84it/s]\u001b[A\n",
            " 85% 1158/1363 [01:25<00:13, 15.53it/s]\u001b[A\n",
            " 85% 1160/1363 [01:25<00:12, 16.49it/s]\u001b[A\n",
            " 85% 1162/1363 [01:25<00:12, 15.63it/s]\u001b[A\n",
            " 85% 1164/1363 [01:25<00:13, 15.15it/s]\u001b[A\n",
            " 86% 1166/1363 [01:25<00:13, 15.02it/s]\u001b[A\n",
            " 86% 1168/1363 [01:25<00:12, 15.05it/s]\u001b[A\n",
            " 86% 1170/1363 [01:26<00:13, 14.15it/s]\u001b[A\n",
            " 86% 1172/1363 [01:26<00:13, 14.16it/s]\u001b[A\n",
            " 86% 1174/1363 [01:26<00:13, 14.43it/s]\u001b[A\n",
            " 86% 1176/1363 [01:26<00:12, 14.49it/s]\u001b[A\n",
            " 86% 1178/1363 [01:26<00:12, 14.97it/s]\u001b[A\n",
            " 87% 1180/1363 [01:26<00:12, 14.66it/s]\u001b[A\n",
            " 87% 1182/1363 [01:26<00:12, 14.97it/s]\u001b[A\n",
            " 87% 1184/1363 [01:27<00:12, 14.74it/s]\u001b[A\n",
            " 87% 1186/1363 [01:27<00:11, 15.35it/s]\u001b[A\n",
            " 87% 1188/1363 [01:27<00:11, 15.70it/s]\u001b[A\n",
            " 87% 1190/1363 [01:27<00:11, 15.65it/s]\u001b[A\n",
            " 87% 1192/1363 [01:27<00:10, 16.56it/s]\u001b[A\n",
            " 88% 1195/1363 [01:27<00:09, 17.01it/s]\u001b[A\n",
            " 88% 1197/1363 [01:27<00:10, 16.26it/s]\u001b[A\n",
            " 88% 1199/1363 [01:27<00:10, 15.01it/s]\u001b[A\n",
            " 88% 1202/1363 [01:28<00:09, 16.59it/s]\u001b[A\n",
            " 88% 1204/1363 [01:28<00:09, 16.36it/s]\u001b[A\n",
            " 88% 1206/1363 [01:28<00:09, 16.38it/s]\u001b[A\n",
            " 89% 1208/1363 [01:28<00:09, 16.36it/s]\u001b[A\n",
            " 89% 1210/1363 [01:28<00:09, 16.69it/s]\u001b[A\n",
            " 89% 1212/1363 [01:28<00:09, 16.37it/s]\u001b[A\n",
            " 89% 1214/1363 [01:28<00:09, 16.39it/s]\u001b[A\n",
            " 89% 1216/1363 [01:28<00:09, 16.33it/s]\u001b[A\n",
            " 89% 1218/1363 [01:29<00:09, 15.99it/s]\u001b[A\n",
            " 90% 1220/1363 [01:29<00:09, 14.99it/s]\u001b[A\n",
            " 90% 1222/1363 [01:29<00:09, 14.59it/s]\u001b[A\n",
            " 90% 1224/1363 [01:29<00:09, 14.82it/s]\u001b[A\n",
            " 90% 1226/1363 [01:29<00:09, 14.94it/s]\u001b[A\n",
            " 90% 1228/1363 [01:29<00:09, 14.60it/s]\u001b[A\n",
            " 90% 1230/1363 [01:29<00:09, 14.44it/s]\u001b[A\n",
            " 90% 1232/1363 [01:30<00:09, 14.40it/s]\u001b[A\n",
            " 91% 1234/1363 [01:30<00:08, 15.35it/s]\u001b[A\n",
            " 91% 1236/1363 [01:30<00:08, 15.55it/s]\u001b[A\n",
            " 91% 1238/1363 [01:30<00:08, 15.02it/s]\u001b[A\n",
            " 91% 1240/1363 [01:30<00:08, 15.22it/s]\u001b[A\n",
            " 91% 1242/1363 [01:30<00:08, 14.38it/s]\u001b[A\n",
            " 91% 1244/1363 [01:30<00:08, 14.86it/s]\u001b[A\n",
            " 91% 1246/1363 [01:30<00:07, 15.18it/s]\u001b[A\n",
            " 92% 1248/1363 [01:31<00:07, 14.92it/s]\u001b[A\n",
            " 92% 1250/1363 [01:31<00:07, 15.37it/s]\u001b[A\n",
            " 92% 1252/1363 [01:31<00:07, 14.81it/s]\u001b[A\n",
            " 92% 1254/1363 [01:31<00:07, 14.53it/s]\u001b[A\n",
            " 92% 1256/1363 [01:31<00:07, 14.98it/s]\u001b[A\n",
            " 92% 1258/1363 [01:31<00:06, 15.00it/s]\u001b[A\n",
            " 92% 1260/1363 [01:31<00:06, 15.33it/s]\u001b[A\n",
            " 93% 1262/1363 [01:32<00:06, 15.05it/s]\u001b[A\n",
            " 93% 1264/1363 [01:32<00:06, 15.51it/s]\u001b[A\n",
            " 93% 1266/1363 [01:32<00:06, 15.27it/s]\u001b[A\n",
            " 93% 1268/1363 [01:32<00:06, 14.70it/s]\u001b[A\n",
            " 93% 1270/1363 [01:32<00:06, 14.26it/s]\u001b[A\n",
            " 93% 1272/1363 [01:32<00:06, 13.76it/s]\u001b[A\n",
            " 93% 1274/1363 [01:32<00:06, 13.89it/s]\u001b[A\n",
            " 94% 1276/1363 [01:33<00:06, 14.25it/s]\u001b[A\n",
            " 94% 1278/1363 [01:33<00:06, 14.00it/s]\u001b[A\n",
            " 94% 1280/1363 [01:33<00:06, 13.69it/s]\u001b[A\n",
            " 94% 1282/1363 [01:33<00:05, 13.76it/s]\u001b[A\n",
            " 94% 1284/1363 [01:33<00:05, 13.69it/s]\u001b[A\n",
            " 94% 1286/1363 [01:33<00:05, 13.46it/s]\u001b[A\n",
            " 94% 1288/1363 [01:33<00:05, 13.07it/s]\u001b[A\n",
            " 95% 1290/1363 [01:34<00:05, 13.19it/s]\u001b[A\n",
            " 95% 1292/1363 [01:34<00:05, 13.39it/s]\u001b[A\n",
            " 95% 1294/1363 [01:34<00:05, 13.38it/s]\u001b[A\n",
            " 95% 1296/1363 [01:34<00:04, 13.45it/s]\u001b[A\n",
            " 95% 1298/1363 [01:34<00:04, 14.12it/s]\u001b[A\n",
            " 95% 1300/1363 [01:34<00:04, 15.28it/s]\u001b[A\n",
            " 96% 1302/1363 [01:34<00:03, 15.53it/s]\u001b[A\n",
            " 96% 1304/1363 [01:35<00:04, 14.29it/s]\u001b[A\n",
            " 96% 1306/1363 [01:35<00:04, 13.79it/s]\u001b[A\n",
            " 96% 1308/1363 [01:35<00:03, 14.05it/s]\u001b[A\n",
            " 96% 1310/1363 [01:35<00:03, 14.33it/s]\u001b[A\n",
            " 96% 1312/1363 [01:35<00:03, 14.61it/s]\u001b[A\n",
            " 96% 1314/1363 [01:35<00:03, 15.05it/s]\u001b[A\n",
            " 97% 1316/1363 [01:35<00:03, 14.44it/s]\u001b[A\n",
            " 97% 1318/1363 [01:36<00:03, 14.52it/s]\u001b[A\n",
            " 97% 1320/1363 [01:36<00:03, 13.79it/s]\u001b[A\n",
            " 97% 1322/1363 [01:36<00:02, 14.16it/s]\u001b[A\n",
            " 97% 1324/1363 [01:36<00:02, 14.62it/s]\u001b[A\n",
            " 97% 1326/1363 [01:36<00:02, 14.27it/s]\u001b[A\n",
            " 97% 1328/1363 [01:36<00:02, 14.12it/s]\u001b[A\n",
            " 98% 1330/1363 [01:36<00:02, 13.73it/s]\u001b[A\n",
            " 98% 1332/1363 [01:37<00:02, 13.44it/s]\u001b[A\n",
            " 98% 1334/1363 [01:37<00:02, 13.56it/s]\u001b[A\n",
            " 98% 1336/1363 [01:37<00:01, 13.84it/s]\u001b[A\n",
            " 98% 1338/1363 [01:37<00:01, 14.15it/s]\u001b[A\n",
            " 98% 1340/1363 [01:37<00:01, 14.34it/s]\u001b[A\n",
            " 98% 1342/1363 [01:37<00:01, 14.67it/s]\u001b[A\n",
            " 99% 1344/1363 [01:37<00:01, 15.12it/s]\u001b[A\n",
            " 99% 1346/1363 [01:37<00:01, 14.71it/s]\u001b[A\n",
            " 99% 1348/1363 [01:38<00:00, 15.00it/s]\u001b[A\n",
            " 99% 1350/1363 [01:38<00:00, 14.69it/s]\u001b[A\n",
            " 99% 1352/1363 [01:38<00:00, 15.01it/s]\u001b[A\n",
            " 99% 1354/1363 [01:38<00:00, 15.06it/s]\u001b[A\n",
            " 99% 1356/1363 [01:38<00:00, 15.06it/s]\u001b[A\n",
            "100% 1358/1363 [01:38<00:00, 14.97it/s]\u001b[A\n",
            "100% 1360/1363 [01:38<00:00, 15.43it/s]\u001b[A\n",
            "100% 1363/1363 [01:39<00:00, 13.75it/s]\n",
            "2025-10-04 09:11:47,787 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:11:47,788 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 3.125e-06\n",
            "2025-10-04 09:11:47,788 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 3.125e-06\n",
            "2025-10-04 09:11:47,788 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 1.1875e-06\n",
            "2025-10-04 09:11:47,789 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:11:47,789 - INFO - machamp.model.trainer - Epoch 1: evaluating on dev\n",
            "100% 4/4 [00:00<00:00, 16.35it/s]\n",
            "2025-10-04 09:11:48,035 - INFO - machamp.model.callback - epoch       : 1/10\n",
            "2025-10-04 09:11:48,035 - INFO - machamp.model.callback - best_epoch  : 1\n",
            "2025-10-04 09:11:48,036 - INFO - machamp.model.callback - max_gpu_mem : 3.4373\n",
            "2025-10-04 09:11:48,036 - INFO - machamp.model.callback - cur_ram     : 2.7168\n",
            "2025-10-04 09:11:48,036 - INFO - machamp.model.callback - time_epoch  : 0:01:39\n",
            "2025-10-04 09:11:48,036 - INFO - machamp.model.callback - time_total  : 0:01:39\n",
            "2025-10-04 09:11:48,036 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:11:48,036 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:11:48,037 - INFO - machamp.model.callback - Best (1)                                                    \n",
            "2025-10-04 09:11:48,037 - INFO - machamp.model.callback - intent_accuracy    75.2443  60.3820       0.3208     0.2900 \n",
            "2025-10-04 09:11:48,037 - INFO - machamp.model.callback - slots_accuracy      1.9704   2.4967       0.5250     0.4469 \n",
            "2025-10-04 09:11:48,037 - INFO - machamp.model.callback - sum                77.2147  62.8787       0.8458     0.7369 \n",
            "2025-10-04 09:11:48,037 - INFO - machamp.model.callback - Epoch 1                                                     \n",
            "2025-10-04 09:11:48,037 - INFO - machamp.model.callback - intent_accuracy    75.2443  60.3820       0.3208     0.2900 \n",
            "2025-10-04 09:11:48,038 - INFO - machamp.model.callback - slots_accuracy      1.9704   2.4967       0.5250     0.4469 \n",
            "2025-10-04 09:11:48,038 - INFO - machamp.model.callback - sum                77.2147  62.8787       0.8458     0.7369 \n",
            "2025-10-04 09:11:48,095 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "││                             \u001b[35m▘\u001b[0m                             │\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │ 0.40\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │ 0.35\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │\n",
            "││                                                           │ 0.30\n",
            "││                             \u001b[34m▖\u001b[0m                             │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            "0.0            0.5            1.0            1.5\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:11:48,096 - INFO - machamp.model.callback - Performance of 0.7369 within top 1 models, saving to logs/nlu/2025.10.04_09.08.43/model_1.pt\n",
            "2025-10-04 09:11:57,652 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:11:57,653 - INFO - machamp.model.trainer - Epoch 2/10: training\n",
            "100% 1363/1363 [05:50<00:00,  3.89it/s]\n",
            "2025-10-04 09:17:48,206 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:17:48,207 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 3.900560461956522e-05\n",
            "2025-10-04 09:17:48,207 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 3.900560461956522e-05\n",
            "2025-10-04 09:17:48,207 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 1.4822129755434783e-05\n",
            "2025-10-04 09:17:48,207 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:17:48,208 - INFO - machamp.model.trainer - Epoch 2: evaluating on dev\n",
            "100% 4/4 [00:00<00:00,  9.52it/s]\n",
            "2025-10-04 09:17:48,630 - INFO - machamp.model.callback - epoch       : 2/10\n",
            "2025-10-04 09:17:48,630 - INFO - machamp.model.callback - best_epoch  : 2\n",
            "2025-10-04 09:17:48,630 - INFO - machamp.model.callback - max_gpu_mem : 6.7761\n",
            "2025-10-04 09:17:48,631 - INFO - machamp.model.callback - cur_ram     : 2.7691\n",
            "2025-10-04 09:17:48,631 - INFO - machamp.model.callback - time_epoch  : 0:05:50\n",
            "2025-10-04 09:17:48,631 - INFO - machamp.model.callback - time_total  : 0:07:39\n",
            "2025-10-04 09:17:48,631 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:17:48,631 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:17:48,631 - INFO - machamp.model.callback - Best (2)                                                    \n",
            "2025-10-04 09:17:48,632 - INFO - machamp.model.callback - intent_accuracy    22.0787  13.0151       0.8134     0.8500 \n",
            "2025-10-04 09:17:48,632 - INFO - machamp.model.callback - slots_accuracy      1.1369   1.9713       0.6919     0.5354 \n",
            "2025-10-04 09:17:48,632 - INFO - machamp.model.callback - sum                23.2156  14.9864       1.5053     1.3854 \n",
            "2025-10-04 09:17:48,632 - INFO - machamp.model.callback - Epoch 2                                                     \n",
            "2025-10-04 09:17:48,632 - INFO - machamp.model.callback - intent_accuracy    22.0787  13.0151       0.8134     0.8500 \n",
            "2025-10-04 09:17:48,632 - INFO - machamp.model.callback - slots_accuracy      1.1369   1.9713       0.6919     0.5354 \n",
            "2025-10-04 09:17:48,633 - INFO - machamp.model.callback - sum                23.2156  14.9864       1.5053     1.3854 \n",
            "2025-10-04 09:17:48,648 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│                                                         \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m│\n",
            "│                                                     \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m   │ 0.8\n",
            "│                                                  \u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m      │\n",
            "│                                              \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m          │\n",
            "│                                          \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m              │\n",
            "│                                       \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m                 │\n",
            "│                                   \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m                     │\n",
            "│                                \u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m                        │ 0.6\n",
            "│                            \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m                            │\n",
            "│                        \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m                    \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m│\n",
            "│                     \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m           │\n",
            "│   \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                                  │\n",
            "│\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m           \u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m                                          │\n",
            "│          \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m                                              │ 0.4\n",
            "│      \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m                                                  │\n",
            "│   \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m                                                     │\n",
            "│\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m                                                         │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            "1.0                           1.5                          2.0\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:17:48,648 - INFO - machamp.model.callback - Performance of 1.3854 within top 1 models, saving to logs/nlu/2025.10.04_09.08.43/model_2.pt\n",
            "2025-10-04 09:18:00,889 - INFO - machamp.model.callback - Removing old model: logs/nlu/2025.10.04_09.08.43/model_1.pt\n",
            "2025-10-04 09:18:00,896 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 09:18:00,896 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_2.pt\n",
            "2025-10-04 09:18:13,080 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:18:13,080 - INFO - machamp.model.trainer - Epoch 3/10: training\n",
            "100% 1363/1363 [05:55<00:00,  3.83it/s]\n",
            "2025-10-04 09:24:08,573 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:24:08,573 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 7.488620923913043e-05\n",
            "2025-10-04 09:24:08,573 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 7.488620923913043e-05\n",
            "2025-10-04 09:24:08,574 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 2.8456759510869565e-05\n",
            "2025-10-04 09:24:08,574 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:24:08,574 - INFO - machamp.model.trainer - Epoch 3: evaluating on dev\n",
            "100% 4/4 [00:00<00:00, 10.16it/s]\n",
            "2025-10-04 09:24:08,970 - INFO - machamp.model.callback - epoch       : 3/10\n",
            "2025-10-04 09:24:08,970 - INFO - machamp.model.callback - best_epoch  : 3\n",
            "2025-10-04 09:24:08,970 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 09:24:08,970 - INFO - machamp.model.callback - cur_ram     : 2.7378\n",
            "2025-10-04 09:24:08,971 - INFO - machamp.model.callback - time_epoch  : 0:05:55\n",
            "2025-10-04 09:24:08,971 - INFO - machamp.model.callback - time_total  : 0:14:00\n",
            "2025-10-04 09:24:08,971 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:24:08,971 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:24:08,971 - INFO - machamp.model.callback - Best (3)                                                    \n",
            "2025-10-04 09:24:08,971 - INFO - machamp.model.callback - intent_accuracy     2.1955  23.1667       0.9832     0.8100 \n",
            "2025-10-04 09:24:08,972 - INFO - machamp.model.callback - slots_accuracy      0.5732   1.4667       0.8287     0.6238 \n",
            "2025-10-04 09:24:08,972 - INFO - machamp.model.callback - sum                 2.7687  24.6334       1.8119     1.4338 \n",
            "2025-10-04 09:24:08,972 - INFO - machamp.model.callback - Epoch 3                                                     \n",
            "2025-10-04 09:24:08,972 - INFO - machamp.model.callback - intent_accuracy     2.1955  23.1667       0.9832     0.8100 \n",
            "2025-10-04 09:24:08,972 - INFO - machamp.model.callback - slots_accuracy      0.5732   1.4667       0.8287     0.6238 \n",
            "2025-10-04 09:24:08,972 - INFO - machamp.model.callback - sum                 2.7687  24.6334       1.8119     1.4338 \n",
            "2025-10-04 09:24:08,987 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│                            \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m           │\n",
            "│                           \u001b[34m▄\u001b[0m\u001b[34m▘\u001b[0m                   \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m│ 0.8\n",
            "│                         \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                                 │\n",
            "│                       \u001b[34m▗\u001b[0m\u001b[34m▀\u001b[0m                                   │\n",
            "│                     \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                                    │\n",
            "│                   \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                                      │\n",
            "│                  \u001b[34m▄\u001b[0m\u001b[34m▘\u001b[0m                                       \u001b[35m▄\u001b[0m│\n",
            "│                \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                             \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m │ 0.6\n",
            "│              \u001b[34m▗\u001b[0m\u001b[34m▀\u001b[0m                    \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m            │\n",
            "│            \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m         \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▛\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                        │\n",
            "│          \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                                   │\n",
            "│ \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                                               │\n",
            "│\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m     \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                                                   │\n",
            "│     \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                                                     │ 0.4\n",
            "│   \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m                                                       │\n",
            "│ \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                                                        │\n",
            "│\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                                                          │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            " 1                             2                            3\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:24:08,987 - INFO - machamp.model.callback - Performance of 1.4338 within top 1 models, saving to logs/nlu/2025.10.04_09.08.43/model_3.pt\n",
            "2025-10-04 09:24:13,744 - INFO - machamp.model.callback - Removing old model: logs/nlu/2025.10.04_09.08.43/model_2.pt\n",
            "2025-10-04 09:24:13,749 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 09:24:13,750 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_3.pt\n",
            "2025-10-04 09:24:31,929 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 09:24:31,930 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_2.pt\n",
            "2025-10-04 09:24:31,934 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:24:31,934 - INFO - machamp.model.trainer - Epoch 4/10: training\n",
            "100% 1363/1363 [05:53<00:00,  3.85it/s]\n",
            "2025-10-04 09:30:25,622 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:30:25,622 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 9.538583032490975e-05\n",
            "2025-10-04 09:30:25,622 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 9.538583032490975e-05\n",
            "2025-10-04 09:30:25,622 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 3.6246615523465705e-05\n",
            "2025-10-04 09:30:25,623 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:30:25,623 - INFO - machamp.model.trainer - Epoch 4: evaluating on dev\n",
            "100% 4/4 [00:00<00:00, 10.11it/s]\n",
            "2025-10-04 09:30:26,020 - INFO - machamp.model.callback - epoch       : 4/10\n",
            "2025-10-04 09:30:26,021 - INFO - machamp.model.callback - best_epoch  : 3\n",
            "2025-10-04 09:30:26,021 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 09:30:26,021 - INFO - machamp.model.callback - cur_ram     : 2.7293\n",
            "2025-10-04 09:30:26,021 - INFO - machamp.model.callback - time_epoch  : 0:05:54\n",
            "2025-10-04 09:30:26,021 - INFO - machamp.model.callback - time_total  : 0:20:17\n",
            "2025-10-04 09:30:26,022 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:30:26,022 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:30:26,022 - INFO - machamp.model.callback - Best (3)                                                    \n",
            "2025-10-04 09:30:26,022 - INFO - machamp.model.callback - intent_accuracy     2.1955  23.1667       0.9832     0.8100 \n",
            "2025-10-04 09:30:26,022 - INFO - machamp.model.callback - slots_accuracy      0.5732   1.4667       0.8287     0.6238 \n",
            "2025-10-04 09:30:26,022 - INFO - machamp.model.callback - sum                 2.7687  24.6334       1.8119     1.4338 \n",
            "2025-10-04 09:30:26,023 - INFO - machamp.model.callback - Epoch 4                                                     \n",
            "2025-10-04 09:30:26,023 - INFO - machamp.model.callback - intent_accuracy     1.5779  30.3087       0.9871     0.7100 \n",
            "2025-10-04 09:30:26,023 - INFO - machamp.model.callback - slots_accuracy      0.3233   1.3607       0.8989     0.6768 \n",
            "2025-10-04 09:30:26,023 - INFO - machamp.model.callback - sum                 1.9012  31.6694       1.8861     1.3868 \n",
            "2025-10-04 09:30:26,045 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│                   \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                           │\n",
            "│                  \u001b[34m▞\u001b[0m             \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                │ 0.8\n",
            "│                 \u001b[34m▞\u001b[0m                         \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m         │\n",
            "│               \u001b[34m▗\u001b[0m\u001b[34m▀\u001b[0m                                 \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m   │\n",
            "│              \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                                         \u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m│\n",
            "│             \u001b[34m▄\u001b[0m\u001b[34m▘\u001b[0m                                    \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m│\n",
            "│            \u001b[34m▞\u001b[0m                          \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m        │\n",
            "│           \u001b[34m▞\u001b[0m                   \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                    │ 0.6\n",
            "│         \u001b[34m▗\u001b[0m\u001b[34m▀\u001b[0m             \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                            │\n",
            "│        \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m      \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▛\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                                    │\n",
            "│       \u001b[34m▄\u001b[0m\u001b[34m▘\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                                           │\n",
            "│ \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                                                   │\n",
            "│\u001b[35m▀\u001b[0m    \u001b[34m▞\u001b[0m                                                      │\n",
            "│   \u001b[34m▗\u001b[0m\u001b[34m▀\u001b[0m                                                       │ 0.4\n",
            "│  \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                                                        │\n",
            "│ \u001b[34m▄\u001b[0m\u001b[34m▘\u001b[0m                                                         │\n",
            "│\u001b[34m▞\u001b[0m                                                           │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            " 1                   2                  3                   4\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:30:26,045 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 09:30:26,045 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_4.pt\n",
            "2025-10-04 09:30:39,135 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 09:30:39,136 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_3.pt\n",
            "2025-10-04 09:30:39,143 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:30:39,145 - INFO - machamp.model.trainer - Epoch 5/10: training\n",
            "100% 1363/1363 [05:52<00:00,  3.86it/s]\n",
            "2025-10-04 09:36:31,871 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:36:31,871 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 8.000902527075813e-05\n",
            "2025-10-04 09:36:31,871 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 8.000902527075813e-05\n",
            "2025-10-04 09:36:31,871 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 3.040342960288809e-05\n",
            "2025-10-04 09:36:31,872 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:36:31,872 - INFO - machamp.model.trainer - Epoch 5: evaluating on dev\n",
            "100% 4/4 [00:00<00:00, 10.77it/s]\n",
            "2025-10-04 09:36:32,246 - INFO - machamp.model.callback - epoch       : 5/10\n",
            "2025-10-04 09:36:32,247 - INFO - machamp.model.callback - best_epoch  : 3\n",
            "2025-10-04 09:36:32,248 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 09:36:32,248 - INFO - machamp.model.callback - cur_ram     : 2.5501\n",
            "2025-10-04 09:36:32,248 - INFO - machamp.model.callback - time_epoch  : 0:05:53\n",
            "2025-10-04 09:36:32,248 - INFO - machamp.model.callback - time_total  : 0:26:23\n",
            "2025-10-04 09:36:32,248 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:36:32,248 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:36:32,249 - INFO - machamp.model.callback - Best (3)                                                    \n",
            "2025-10-04 09:36:32,249 - INFO - machamp.model.callback - intent_accuracy     2.1955  23.1667       0.9832     0.8100 \n",
            "2025-10-04 09:36:32,249 - INFO - machamp.model.callback - slots_accuracy      0.5732   1.4667       0.8287     0.6238 \n",
            "2025-10-04 09:36:32,249 - INFO - machamp.model.callback - sum                 2.7687  24.6334       1.8119     1.4338 \n",
            "2025-10-04 09:36:32,249 - INFO - machamp.model.callback - Epoch 5                                                     \n",
            "2025-10-04 09:36:32,249 - INFO - machamp.model.callback - intent_accuracy     1.1766  20.9842       0.9903     0.7800 \n",
            "2025-10-04 09:36:32,249 - INFO - machamp.model.callback - slots_accuracy      0.2138   1.2274       0.9328     0.6527 \n",
            "2025-10-04 09:36:32,250 - INFO - machamp.model.callback - sum                 1.3903  22.2116       1.9231     1.4327 \n",
            "2025-10-04 09:36:32,379 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│              \u001b[34m▗\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                       │\n",
            "│              \u001b[34m▞\u001b[0m     \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                │\n",
            "│             \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m            \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m                            │ 0.8\n",
            "│             \u001b[34m▞\u001b[0m                  \u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                        \u001b[34m▗\u001b[0m│\n",
            "│            \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                    \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                 \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m│\n",
            "│            \u001b[34m▞\u001b[0m                        \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m          \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m    │\n",
            "│           \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                           \u001b[34m▝\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m    \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m        │\n",
            "│           \u001b[34m▞\u001b[0m                               \u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m            │\n",
            "│          \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                                                │\n",
            "│          \u001b[34m▞\u001b[0m                              \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m       │\n",
            "│         \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                         \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m          \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▄\u001b[0m│\n",
            "│         \u001b[34m▞\u001b[0m                    \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                        │\n",
            "│        \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                 \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                             │\n",
            "│        \u001b[34m▞\u001b[0m               \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m                                 │ 0.6\n",
            "│       \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m            \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m                                    │\n",
            "│       \u001b[34m▞\u001b[0m         \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                                       │\n",
            "│      \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m      \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                                          │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            " 1              2              3             4              5\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:36:32,379 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 09:36:32,379 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_5.pt\n",
            "2025-10-04 09:36:58,520 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 09:36:58,521 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_4.pt\n",
            "2025-10-04 09:36:58,527 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:36:58,527 - INFO - machamp.model.trainer - Epoch 6/10: training\n",
            "100% 1363/1363 [05:52<00:00,  3.87it/s]\n",
            "2025-10-04 09:42:50,720 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:42:50,721 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 6.46322202166065e-05\n",
            "2025-10-04 09:42:50,721 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 6.46322202166065e-05\n",
            "2025-10-04 09:42:50,721 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 2.4560243682310474e-05\n",
            "2025-10-04 09:42:50,721 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:42:50,721 - INFO - machamp.model.trainer - Epoch 6: evaluating on dev\n",
            "100% 4/4 [00:00<00:00, 10.25it/s]\n",
            "2025-10-04 09:42:51,114 - INFO - machamp.model.callback - epoch       : 6/10\n",
            "2025-10-04 09:42:51,114 - INFO - machamp.model.callback - best_epoch  : 6\n",
            "2025-10-04 09:42:51,114 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 09:42:51,115 - INFO - machamp.model.callback - cur_ram     : 2.3487\n",
            "2025-10-04 09:42:51,115 - INFO - machamp.model.callback - time_epoch  : 0:05:52\n",
            "2025-10-04 09:42:51,115 - INFO - machamp.model.callback - time_total  : 0:32:42\n",
            "2025-10-04 09:42:51,115 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:42:51,115 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:42:51,116 - INFO - machamp.model.callback - Best (6)                                                    \n",
            "2025-10-04 09:42:51,116 - INFO - machamp.model.callback - intent_accuracy     0.8986  16.0703       0.9924     0.8100 \n",
            "2025-10-04 09:42:51,116 - INFO - machamp.model.callback - slots_accuracy      0.1666   1.1297       0.9478     0.7122 \n",
            "2025-10-04 09:42:51,116 - INFO - machamp.model.callback - sum                 1.0652  17.2000       1.9402     1.5222 \n",
            "2025-10-04 09:42:51,116 - INFO - machamp.model.callback - Epoch 6                                                     \n",
            "2025-10-04 09:42:51,116 - INFO - machamp.model.callback - intent_accuracy     0.8986  16.0703       0.9924     0.8100 \n",
            "2025-10-04 09:42:51,116 - INFO - machamp.model.callback - slots_accuracy      0.1666   1.1297       0.9478     0.7122 \n",
            "2025-10-04 09:42:51,117 - INFO - machamp.model.callback - sum                 1.0652  17.2000       1.9402     1.5222 \n",
            "2025-10-04 09:42:51,133 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│           \u001b[34m▗\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                           │\n",
            "│           \u001b[34m▐\u001b[0m    \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m                                      │\n",
            "│           \u001b[34m▌\u001b[0m          \u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▖\u001b[0m                             \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m│ 0.8\n",
            "│          \u001b[34m▐\u001b[0m              \u001b[34m▝\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m                   \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m     │\n",
            "│          \u001b[34m▞\u001b[0m                 \u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m              \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m            │\n",
            "│         \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                   \u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m        \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m               │\n",
            "│         \u001b[34m▐\u001b[0m                      \u001b[34m▝\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▖\u001b[0m   \u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m                   │\n",
            "│         \u001b[34m▌\u001b[0m                        \u001b[34m▝\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m                    \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m│\n",
            "│        \u001b[34m▐\u001b[0m                                             \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m  │\n",
            "│        \u001b[34m▞\u001b[0m                        \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m        \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m      │\n",
            "│       \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m                    \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m         \u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m          │\n",
            "│       \u001b[34m▐\u001b[0m                \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                               │\n",
            "│       \u001b[34m▌\u001b[0m              \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                                   │\n",
            "│      \u001b[34m▐\u001b[0m            \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m                                      │ 0.6\n",
            "│      \u001b[34m▞\u001b[0m         \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                         │\n",
            "│     \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m       \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                           │\n",
            "│     \u001b[34m▐\u001b[0m     \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                              │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            " 1           2           3          4           5           6\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:42:51,133 - INFO - machamp.model.callback - Performance of 1.5222 within top 1 models, saving to logs/nlu/2025.10.04_09.08.43/model_6.pt\n",
            "2025-10-04 09:42:55,775 - INFO - machamp.model.callback - Removing old model: logs/nlu/2025.10.04_09.08.43/model_3.pt\n",
            "2025-10-04 09:42:55,778 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 09:42:55,778 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_6.pt\n",
            "2025-10-04 09:43:10,306 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 09:43:10,308 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_5.pt\n",
            "2025-10-04 09:43:10,318 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:43:10,318 - INFO - machamp.model.trainer - Epoch 7/10: training\n",
            "100% 1363/1363 [05:56<00:00,  3.83it/s]\n",
            "2025-10-04 09:49:06,354 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:49:06,355 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 4.9255415162454885e-05\n",
            "2025-10-04 09:49:06,355 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 4.9255415162454885e-05\n",
            "2025-10-04 09:49:06,356 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 1.8717057761732857e-05\n",
            "2025-10-04 09:49:06,356 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:49:06,356 - INFO - machamp.model.trainer - Epoch 7: evaluating on dev\n",
            "100% 4/4 [00:00<00:00, 10.95it/s]\n",
            "2025-10-04 09:49:06,723 - INFO - machamp.model.callback - epoch       : 7/10\n",
            "2025-10-04 09:49:06,724 - INFO - machamp.model.callback - best_epoch  : 6\n",
            "2025-10-04 09:49:06,724 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 09:49:06,724 - INFO - machamp.model.callback - cur_ram     : 2.2387\n",
            "2025-10-04 09:49:06,724 - INFO - machamp.model.callback - time_epoch  : 0:05:56\n",
            "2025-10-04 09:49:06,725 - INFO - machamp.model.callback - time_total  : 0:38:58\n",
            "2025-10-04 09:49:06,725 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:49:06,725 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:49:06,725 - INFO - machamp.model.callback - Best (6)                                                    \n",
            "2025-10-04 09:49:06,725 - INFO - machamp.model.callback - intent_accuracy     0.8986  16.0703       0.9924     0.8100 \n",
            "2025-10-04 09:49:06,726 - INFO - machamp.model.callback - slots_accuracy      0.1666   1.1297       0.9478     0.7122 \n",
            "2025-10-04 09:49:06,726 - INFO - machamp.model.callback - sum                 1.0652  17.2000       1.9402     1.5222 \n",
            "2025-10-04 09:49:06,726 - INFO - machamp.model.callback - Epoch 7                                                     \n",
            "2025-10-04 09:49:06,726 - INFO - machamp.model.callback - intent_accuracy     0.7312  27.1000       0.9932     0.7800 \n",
            "2025-10-04 09:49:06,726 - INFO - machamp.model.callback - slots_accuracy      0.1359   1.2876       0.9577     0.6801 \n",
            "2025-10-04 09:49:06,726 - INFO - machamp.model.callback - sum                 0.8672  28.3876       1.9509     1.4601 \n",
            "2025-10-04 09:49:06,744 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│          \u001b[34m▛\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                              │\n",
            "│         \u001b[34m▐\u001b[0m   \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                         │\n",
            "│         \u001b[34m▞\u001b[0m        \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▖\u001b[0m                        \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m      │ 0.8\n",
            "│         \u001b[34m▌\u001b[0m           \u001b[34m▝\u001b[0m\u001b[34m▄\u001b[0m                \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m       \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m│\n",
            "│        \u001b[34m▐\u001b[0m              \u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m            \u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                    │\n",
            "│        \u001b[34m▞\u001b[0m                \u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m       \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m                       │\n",
            "│        \u001b[34m▌\u001b[0m                  \u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m  \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m                         │\n",
            "│       \u001b[34m▐\u001b[0m                     \u001b[34m▀\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                \u001b[35m▄\u001b[0m\u001b[35m▟\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m       │\n",
            "│       \u001b[34m▞\u001b[0m                                     \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m     \u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m │\n",
            "│       \u001b[34m▌\u001b[0m                   \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m       \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m             \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m│\n",
            "│      \u001b[34m▐\u001b[0m                 \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m       \u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                  │\n",
            "│      \u001b[34m▞\u001b[0m             \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m                                    │\n",
            "│     \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m           \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                       │\n",
            "│     \u001b[34m▐\u001b[0m          \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                          │ 0.6\n",
            "│     \u001b[34m▌\u001b[0m        \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                            │\n",
            "│    \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m      \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                              │\n",
            "│    \u001b[34m▐\u001b[0m    \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m                                                │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            " 1         2         3         4        5         6         7\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:49:06,744 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 09:49:06,745 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_7.pt\n",
            "2025-10-04 09:49:17,192 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 09:49:17,193 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_6.pt\n",
            "2025-10-04 09:49:17,195 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:49:17,195 - INFO - machamp.model.trainer - Epoch 8/10: training\n",
            "100% 1363/1363 [06:12<00:00,  3.66it/s]\n",
            "2025-10-04 09:55:29,392 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 09:55:29,393 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 3.387861010830326e-05\n",
            "2025-10-04 09:55:29,393 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 3.387861010830326e-05\n",
            "2025-10-04 09:55:29,393 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 1.2873871841155236e-05\n",
            "2025-10-04 09:55:29,394 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 09:55:29,394 - INFO - machamp.model.trainer - Epoch 8: evaluating on dev\n",
            "100% 4/4 [00:00<00:00,  9.88it/s]\n",
            "2025-10-04 09:55:29,802 - INFO - machamp.model.callback - epoch       : 8/10\n",
            "2025-10-04 09:55:29,802 - INFO - machamp.model.callback - best_epoch  : 8\n",
            "2025-10-04 09:55:29,802 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 09:55:29,802 - INFO - machamp.model.callback - cur_ram     : 2.1574\n",
            "2025-10-04 09:55:29,803 - INFO - machamp.model.callback - time_epoch  : 0:06:12\n",
            "2025-10-04 09:55:29,803 - INFO - machamp.model.callback - time_total  : 0:45:21\n",
            "2025-10-04 09:55:29,803 - INFO - machamp.model.callback - \n",
            "2025-10-04 09:55:29,803 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 09:55:29,803 - INFO - machamp.model.callback - Best (8)                                                    \n",
            "2025-10-04 09:55:29,803 - INFO - machamp.model.callback - intent_accuracy     0.5149  19.4980       0.9953     0.8100 \n",
            "2025-10-04 09:55:29,804 - INFO - machamp.model.callback - slots_accuracy      0.1148   1.1670       0.9639     0.7170 \n",
            "2025-10-04 09:55:29,804 - INFO - machamp.model.callback - sum                 0.6297  20.6649       1.9592     1.5270 \n",
            "2025-10-04 09:55:29,804 - INFO - machamp.model.callback - Epoch 8                                                     \n",
            "2025-10-04 09:55:29,804 - INFO - machamp.model.callback - intent_accuracy     0.5149  19.4980       0.9953     0.8100 \n",
            "2025-10-04 09:55:29,804 - INFO - machamp.model.callback - slots_accuracy      0.1148   1.1670       0.9639     0.7170 \n",
            "2025-10-04 09:55:29,804 - INFO - machamp.model.callback - sum                 0.6297  20.6649       1.9592     1.5270 \n",
            "2025-10-04 09:55:29,830 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│        \u001b[34m▐\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                                │\n",
            "│        \u001b[34m▞\u001b[0m  \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m                                            │\n",
            "│        \u001b[34m▌\u001b[0m       \u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▖\u001b[0m                    \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m          \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m│ 0.8\n",
            "│       \u001b[34m▐\u001b[0m          \u001b[34m▝\u001b[0m\u001b[34m▄\u001b[0m              \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m      \u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m   │\n",
            "│       \u001b[34m▞\u001b[0m            \u001b[34m▚\u001b[0m\u001b[34m▖\u001b[0m          \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                          │\n",
            "│       \u001b[34m▌\u001b[0m             \u001b[34m▝\u001b[0m\u001b[34m▚\u001b[0m      \u001b[34m▗\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m                            │\n",
            "│      \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m               \u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m  \u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                              │\n",
            "│      \u001b[34m▐\u001b[0m                  \u001b[34m▚\u001b[0m\u001b[34m▀\u001b[0m              \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m          \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m│\n",
            "│      \u001b[34m▌\u001b[0m                               \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m   \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m \u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m   │\n",
            "│      \u001b[34m▌\u001b[0m                 \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m      \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m           \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m        │\n",
            "│     \u001b[34m▐\u001b[0m              \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m      \u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m                        │\n",
            "│     \u001b[34m▞\u001b[0m           \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                                       │\n",
            "│     \u001b[34m▌\u001b[0m         \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                          │\n",
            "│    \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m        \u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                            │ 0.6\n",
            "│    \u001b[34m▐\u001b[0m       \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                              │\n",
            "│    \u001b[34m▌\u001b[0m     \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                                │\n",
            "│    \u001b[34m▌\u001b[0m   \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m                                                  │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            "         2                4                6                8\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 09:55:29,830 - INFO - machamp.model.callback - Performance of 1.5270 within top 1 models, saving to logs/nlu/2025.10.04_09.08.43/model_8.pt\n",
            "2025-10-04 09:55:45,421 - INFO - machamp.model.callback - Removing old model: logs/nlu/2025.10.04_09.08.43/model_6.pt\n",
            "2025-10-04 09:55:45,423 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 09:55:45,424 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_8.pt\n",
            "2025-10-04 09:56:28,057 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 09:56:28,059 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_7.pt\n",
            "2025-10-04 09:56:28,064 - INFO - machamp.model.trainer - \n",
            "2025-10-04 09:56:28,065 - INFO - machamp.model.trainer - Epoch 9/10: training\n",
            "100% 1363/1363 [06:13<00:00,  3.65it/s]\n",
            "2025-10-04 10:02:41,404 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 10:02:41,404 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 1.8501805054151626e-05\n",
            "2025-10-04 10:02:41,404 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 1.8501805054151626e-05\n",
            "2025-10-04 10:02:41,405 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 7.030685920577618e-06\n",
            "2025-10-04 10:02:41,405 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 10:02:41,405 - INFO - machamp.model.trainer - Epoch 9: evaluating on dev\n",
            "100% 4/4 [00:00<00:00,  9.73it/s]\n",
            "2025-10-04 10:02:41,840 - INFO - machamp.model.callback - epoch       : 9/10\n",
            "2025-10-04 10:02:41,840 - INFO - machamp.model.callback - best_epoch  : 9\n",
            "2025-10-04 10:02:41,840 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 10:02:41,840 - INFO - machamp.model.callback - cur_ram     : 1.9955\n",
            "2025-10-04 10:02:41,841 - INFO - machamp.model.callback - time_epoch  : 0:06:13\n",
            "2025-10-04 10:02:41,841 - INFO - machamp.model.callback - time_total  : 0:52:33\n",
            "2025-10-04 10:02:41,841 - INFO - machamp.model.callback - \n",
            "2025-10-04 10:02:41,841 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 10:02:41,841 - INFO - machamp.model.callback - Best (9)                                                    \n",
            "2025-10-04 10:02:41,842 - INFO - machamp.model.callback - intent_accuracy     0.3807  17.7164       0.9962     0.8400 \n",
            "2025-10-04 10:02:41,842 - INFO - machamp.model.callback - slots_accuracy      0.1019   1.1430       0.9681     0.7090 \n",
            "2025-10-04 10:02:41,842 - INFO - machamp.model.callback - sum                 0.4826  18.8594       1.9643     1.5490 \n",
            "2025-10-04 10:02:41,842 - INFO - machamp.model.callback - Epoch 9                                                     \n",
            "2025-10-04 10:02:41,842 - INFO - machamp.model.callback - intent_accuracy     0.3807  17.7164       0.9962     0.8400 \n",
            "2025-10-04 10:02:41,842 - INFO - machamp.model.callback - slots_accuracy      0.1019   1.1430       0.9681     0.7090 \n",
            "2025-10-04 10:02:41,842 - INFO - machamp.model.callback - sum                 0.4826  18.8594       1.9643     1.5490 \n",
            "2025-10-04 10:02:41,922 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│       \u001b[34m▐\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                                \u001b[34m▄\u001b[0m│\n",
            "│       \u001b[34m▌\u001b[0m  \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m                                        \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m │\n",
            "│       \u001b[34m▌\u001b[0m      \u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m                  \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m        \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m      │ 0.8\n",
            "│      \u001b[34m▐\u001b[0m         \u001b[34m▀\u001b[0m\u001b[34m▖\u001b[0m            \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m     \u001b[34m▝\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m          │\n",
            "│      \u001b[34m▐\u001b[0m          \u001b[34m▝\u001b[0m\u001b[34m▄\u001b[0m         \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                              │\n",
            "│      \u001b[34m▌\u001b[0m            \u001b[34m▚\u001b[0m\u001b[34m▖\u001b[0m     \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                                │\n",
            "│      \u001b[34m▌\u001b[0m             \u001b[34m▝\u001b[0m\u001b[34m▖\u001b[0m  \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                                  │\n",
            "│     \u001b[34m▐\u001b[0m               \u001b[34m▝\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▀\u001b[0m            \u001b[35m▄\u001b[0m\u001b[35m▙\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m         \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m│\n",
            "│     \u001b[34m▐\u001b[0m                            \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m   \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m          │\n",
            "│     \u001b[34m▌\u001b[0m               \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m    \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m          \u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m              │\n",
            "│     \u001b[34m▌\u001b[0m            \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m     \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                            │\n",
            "│    \u001b[34m▐\u001b[0m          \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                          │\n",
            "│    \u001b[34m▐\u001b[0m        \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                            │\n",
            "│    \u001b[34m▌\u001b[0m       \u001b[35m▄\u001b[0m\u001b[35m▘\u001b[0m                                              │ 0.6\n",
            "│    \u001b[34m▌\u001b[0m     \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m                                                │\n",
            "│   \u001b[34m▐\u001b[0m     \u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                                 │\n",
            "│   \u001b[34m▐\u001b[0m   \u001b[35m▗\u001b[0m\u001b[35m▀\u001b[0m                                                   │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            "        2              4              6              8\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 10:02:41,923 - INFO - machamp.model.callback - Performance of 1.5490 within top 1 models, saving to logs/nlu/2025.10.04_09.08.43/model_9.pt\n",
            "2025-10-04 10:02:46,802 - INFO - machamp.model.callback - Removing old model: logs/nlu/2025.10.04_09.08.43/model_8.pt\n",
            "2025-10-04 10:02:46,805 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 10:02:46,805 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_9.pt\n",
            "2025-10-04 10:02:57,943 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 10:02:57,944 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_8.pt\n",
            "2025-10-04 10:02:57,948 - INFO - machamp.model.trainer - \n",
            "2025-10-04 10:02:57,948 - INFO - machamp.model.trainer - Epoch 10/10: training\n",
            "100% 1363/1363 [05:54<00:00,  3.84it/s]\n",
            "2025-10-04 10:08:52,672 - INFO - machamp.modules.allennlp.slanted_triangular - Learning rates for each group: \n",
            "\n",
            "2025-10-04 10:08:52,672 - INFO - machamp.modules.allennlp.slanted_triangular - 0: 3.125e-06\n",
            "2025-10-04 10:08:52,672 - INFO - machamp.modules.allennlp.slanted_triangular - 1: 3.125e-06\n",
            "2025-10-04 10:08:52,673 - INFO - machamp.modules.allennlp.slanted_triangular - 2: 1.1875e-06\n",
            "2025-10-04 10:08:52,673 - INFO - machamp.modules.allennlp.slanted_triangular - Gradual unfreezing finished. Training all layers.\n",
            "2025-10-04 10:08:52,673 - INFO - machamp.model.trainer - Epoch 10: evaluating on dev\n",
            "100% 4/4 [00:00<00:00,  9.57it/s]\n",
            "2025-10-04 10:08:53,099 - INFO - machamp.model.callback - epoch       : 10/10\n",
            "2025-10-04 10:08:53,100 - INFO - machamp.model.callback - best_epoch  : 10\n",
            "2025-10-04 10:08:53,100 - INFO - machamp.model.callback - max_gpu_mem : 6.7815\n",
            "2025-10-04 10:08:53,100 - INFO - machamp.model.callback - cur_ram     : 1.9966\n",
            "2025-10-04 10:08:53,101 - INFO - machamp.model.callback - time_epoch  : 0:05:55\n",
            "2025-10-04 10:08:53,101 - INFO - machamp.model.callback - time_total  : 0:58:44\n",
            "2025-10-04 10:08:53,101 - INFO - machamp.model.callback - \n",
            "2025-10-04 10:08:53,101 - INFO - machamp.model.callback -                 train_loss dev_loss train_scores dev_scores \n",
            "2025-10-04 10:08:53,101 - INFO - machamp.model.callback - Best (10)                                                   \n",
            "2025-10-04 10:08:53,101 - INFO - machamp.model.callback - intent_accuracy     0.2670  18.0857       0.9973     0.8400 \n",
            "2025-10-04 10:08:53,102 - INFO - machamp.model.callback - slots_accuracy      0.0940   1.1283       0.9703     0.7138 \n",
            "2025-10-04 10:08:53,102 - INFO - machamp.model.callback - sum                 0.3610  19.2140       1.9676     1.5538 \n",
            "2025-10-04 10:08:53,102 - INFO - machamp.model.callback - Epoch 10                                                    \n",
            "2025-10-04 10:08:53,102 - INFO - machamp.model.callback - intent_accuracy     0.2670  18.0857       0.9973     0.8400 \n",
            "2025-10-04 10:08:53,102 - INFO - machamp.model.callback - slots_accuracy      0.0940   1.1283       0.9703     0.7138 \n",
            "2025-10-04 10:08:53,103 - INFO - machamp.model.callback - sum                 0.3610  19.2140       1.9676     1.5538 \n",
            "2025-10-04 10:08:53,155 - INFO - machamp.model.callback - \n",
            "                Dev scores (y) over epochs (x)\n",
            "┌────────────────────────────────────────────────────────────┐\n",
            "│      \u001b[34m▐\u001b[0m\u001b[34m▚\u001b[0m\u001b[34m▄\u001b[0m                                           \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m│\n",
            "│      \u001b[34m▐\u001b[0m  \u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▖\u001b[0m                                   \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m       │\n",
            "│      \u001b[34m▌\u001b[0m     \u001b[34m▝\u001b[0m\u001b[34m▜\u001b[0m\u001b[34m▖\u001b[0m               \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m        \u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m            │ 0.8\n",
            "│      \u001b[34m▌\u001b[0m       \u001b[34m▝\u001b[0m\u001b[34m▖\u001b[0m          \u001b[34m▗\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▞\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▘\u001b[0m     \u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m\u001b[34m▀\u001b[0m                │\n",
            "│     \u001b[34m▗\u001b[0m\u001b[34m▘\u001b[0m        \u001b[34m▝\u001b[0m\u001b[34m▄\u001b[0m        \u001b[34m▞\u001b[0m\u001b[34m▘\u001b[0m                                 │\n",
            "│     \u001b[34m▐\u001b[0m           \u001b[34m▚\u001b[0m     \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                                   │\n",
            "│     \u001b[34m▞\u001b[0m            \u001b[34m▚\u001b[0m\u001b[34m▖\u001b[0m \u001b[34m▄\u001b[0m\u001b[34m▀\u001b[0m                                     │\n",
            "│     \u001b[34m▌\u001b[0m             \u001b[34m▝\u001b[0m\u001b[34m▞\u001b[0m           \u001b[35m▄\u001b[0m\u001b[35m▙\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m        \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▚\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m│\n",
            "│     \u001b[34m▌\u001b[0m                        \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m   \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m \u001b[35m▗\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m                │\n",
            "│    \u001b[34m▐\u001b[0m             \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▖\u001b[0m    \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m         \u001b[35m▀\u001b[0m\u001b[35m▘\u001b[0m                   │\n",
            "│    \u001b[34m▐\u001b[0m           \u001b[35m▄\u001b[0m\u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m    \u001b[35m▝\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▀\u001b[0m\u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                │\n",
            "│    \u001b[34m▌\u001b[0m         \u001b[35m▄\u001b[0m\u001b[35m▀\u001b[0m                                            │\n",
            "│    \u001b[34m▌\u001b[0m       \u001b[35m▗\u001b[0m\u001b[35m▀\u001b[0m                                              │\n",
            "│   \u001b[34m▐\u001b[0m       \u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                               │ 0.6\n",
            "│   \u001b[34m▐\u001b[0m     \u001b[35m▗\u001b[0m\u001b[35m▀\u001b[0m                                                 │\n",
            "│   \u001b[34m▞\u001b[0m    \u001b[35m▞\u001b[0m\u001b[35m▘\u001b[0m                                                  │\n",
            "│   \u001b[34m▌\u001b[0m  \u001b[35m▗\u001b[0m\u001b[35m▞\u001b[0m                                                    │\n",
            "└────────────────────────────────────────────────────────────┘\n",
            "       2             4            6            8           10\n",
            "                     \u001b[34m██\u001b[0m intent   \u001b[35m██\u001b[0m slots\n",
            "2025-10-04 10:08:53,155 - INFO - machamp.model.callback - Performance of 1.5538 within top 1 models, saving to logs/nlu/2025.10.04_09.08.43/model_10.pt\n",
            "2025-10-04 10:08:59,007 - INFO - machamp.model.callback - Removing old model: logs/nlu/2025.10.04_09.08.43/model_9.pt\n",
            "2025-10-04 10:08:59,012 - INFO - machamp.model.callback - Best performance obtained in epoch 10 linking model model_10.pt as logs/nlu/2025.10.04_09.08.43/model.pt.\n",
            "2025-10-04 10:08:59,064 - INFO - machamp.model.trainer - Saving training state, so that we can use --resume if needed\n",
            "2025-10-04 10:08:59,064 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_10.pt\n",
            "2025-10-04 10:09:12,907 - INFO - machamp.model.trainer - Removing old training state.\n",
            "2025-10-04 10:09:12,908 - INFO - machamp.model.trainer - Path: logs/nlu/2025.10.04_09.08.43/train_state_epoch_9.pt\n",
            "2025-10-04 10:09:12,917 - INFO - machamp.model.trainer - \n",
            "2025-10-04 10:09:13,200 - INFO - machamp.model.trainer - Predicting on dev set\n",
            "2025-10-04 10:09:20,385 - INFO - machamp.data.machamp_dataset - Reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/final_not_full_tat.valid.conll...\n",
            "2025-10-04 10:09:20,524 - INFO - machamp.readers.read_sequence - Stats NLU (/content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/final_not_full_tat.valid.conll):\n",
            "2025-10-04 10:09:20,525 - INFO - machamp.readers.read_sequence - Lines:      100\n",
            "2025-10-04 10:09:20,525 - INFO - machamp.readers.read_sequence - Words:      622\n",
            "2025-10-04 10:09:20,525 - INFO - machamp.readers.read_sequence - Subwords:   1,438\n",
            "2025-10-04 10:09:20,525 - INFO - machamp.readers.read_sequence - Unks:       0\n",
            "2025-10-04 10:09:20,526 - INFO - machamp.readers.read_sequence - Pre-splits: 0\n",
            "2025-10-04 10:09:20,526 - INFO - machamp.data.machamp_dataset - Done reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/final_not_full_tat.valid.conll (0.0s)\n",
            "\n",
            "100% 4/4 [00:00<00:00,  6.80it/s]\n",
            "2025-10-04 10:09:21,129 - INFO - machamp.utils.myutils - intent_accuracy : 0.8400\n",
            "2025-10-04 10:09:21,130 - INFO - machamp.utils.myutils - slots_accuracy  : 0.7138\n",
            "2025-10-04 10:09:21,131 - INFO - machamp.utils.myutils - sum             : 1.5538\n",
            "2025-10-04 10:09:21,131 - INFO - machamp.utils.myutils - \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/drive/MyDrive/Colab_Notebooks/machamp/train.py --dataset_configs /content/drive/MyDrive/Colab_Notebooks/machamp/configs/nlu.json --device 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xa3fhtStJP_b"
      },
      "outputs": [],
      "source": [
        "%mkdir /content/drive/MyDrive/Colab_Notebooks/machamp/predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG-9w5D5I9b3",
        "outputId": "03b51ede-4aeb-48ea-896a-a73025cd62cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-04 10:32:02.991894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759573923.012652   24769 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759573923.019850   24769 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759573923.036431   24769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759573923.036457   24769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759573923.036460   24769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759573923.036466   24769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-04 10:32:03.041457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-10-04 10:32:06,439 - INFO - __main__ - cmd: predict.py /content/drive/MyDrive/Colab_Notebooks/machamp/logs/nlu/2025.10.04_09.08.43/model_10.pt /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/tt.test_final.replaced.conll /content/drive/MyDrive/Colab_Notebooks/machamp/predictions/nlu.xsid.out --device 0\n",
            "\n",
            "2025-10-04 10:32:06,440 - INFO - __main__ - loading model...\n",
            "2025-10-04 10:32:09,896 - INFO - __main__ - predicting on /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/tt.test_final.replaced.conll, saving on /content/drive/MyDrive/Colab_Notebooks/machamp/predictions/nlu.xsid.out\n",
            "2025-10-04 10:32:11,110 - INFO - machamp.data.machamp_dataset - Reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/tt.test_final.replaced.conll...\n",
            "2025-10-04 10:32:11,147 - WARNING - machamp.data.machamp_vocabulary -  reminder/show_reminders can not be found in namespace intent. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,246 - WARNING - machamp.data.machamp_vocabulary - alarm/snooze_alarm can not be found in namespace slots. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,264 - WARNING - machamp.data.machamp_vocabulary -  reminder/show_reminders can not be found in namespace intent. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,313 - WARNING - machamp.data.machamp_vocabulary - I-party_size_number can not be found in namespace slots. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,389 - WARNING - machamp.data.machamp_vocabulary - I-rating_value can not be found in namespace slots. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,433 - WARNING - machamp.data.machamp_vocabulary - I-condition_description can not be found in namespace slots. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,478 - WARNING - machamp.data.machamp_vocabulary - RateBook can not be found in namespace slots. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,479 - WARNING - machamp.data.machamp_vocabulary - RateBook can not be found in namespace slots. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,519 - WARNING - machamp.data.machamp_vocabulary - B-oobject_type can not be found in namespace slots. This usually means you have unseen labels in your data during prediction. This will lead to incorrect macro-f1 scores.\n",
            "2025-10-04 10:32:11,528 - INFO - machamp.readers.read_sequence - Stats NLU (/content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/tt.test_final.replaced.conll):\n",
            "2025-10-04 10:32:11,528 - INFO - machamp.readers.read_sequence - Lines:      500\n",
            "2025-10-04 10:32:11,528 - INFO - machamp.readers.read_sequence - Words:      2,952\n",
            "2025-10-04 10:32:11,528 - INFO - machamp.readers.read_sequence - Subwords:   7,044\n",
            "2025-10-04 10:32:11,528 - INFO - machamp.readers.read_sequence - Unks:       0\n",
            "2025-10-04 10:32:11,528 - INFO - machamp.readers.read_sequence - Pre-splits: 0\n",
            "2025-10-04 10:32:11,529 - INFO - machamp.data.machamp_dataset - Done reading /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/tt.test_final.replaced.conll (0.0s)\n",
            "\n",
            "100% 16/16 [00:03<00:00,  4.80it/s]\n",
            "2025-10-04 10:32:14,870 - INFO - machamp.utils.myutils - intent_accuracy : 0.8540\n",
            "2025-10-04 10:32:14,870 - INFO - machamp.utils.myutils - slots_accuracy  : 0.6992\n",
            "2025-10-04 10:32:14,870 - INFO - machamp.utils.myutils - sum             : 1.5532\n",
            "2025-10-04 10:32:14,870 - INFO - machamp.utils.myutils - \n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 predict.py /content/drive/MyDrive/Colab_Notebooks/machamp/logs/nlu/2025.10.04_09.08.43/model_10.pt /content/drive/MyDrive/Colab_Notebooks/machamp/data/xSID-tat/tt.test_final.replaced.conll /content/drive/MyDrive/Colab_Notebooks/machamp/predictions/nlu.xsid.out --device 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8dZ8ef6zRtg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}